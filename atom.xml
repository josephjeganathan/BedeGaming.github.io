<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Bede Engineering]]></title>
  <link href="http://engineering.bedegaming.com/atom.xml" rel="self"/>
  <link href="http://engineering.bedegaming.com/"/>
  <updated>2015-04-22T13:37:32+00:00</updated>
  <id>http://engineering.bedegaming.com/</id>
  <author>
    <name><![CDATA[Bede Gaming Ltd]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Orchestra - The Journey of a Javascript Framework Part 1]]></title>
    <link href="http://engineering.bedegaming.com/blog/2015/04/16/orchestra-the-journey-of-a-javascript-framework/"/>
    <updated>2015-04-16T14:00:00+00:00</updated>
    <id>http://engineering.bedegaming.com/blog/2015/04/16/orchestra-the-journey-of-a-javascript-framework</id>
    <content type="html"><![CDATA[<p>Recently I&rsquo;ve been excitedly talking to my colleagues about Orchestra, a &ldquo;Super awesome framework&rdquo; we have built in the Bede Games Studio, so I thought I&rsquo;d give them all a break a write a blog post about it instead!</p>

<!-- more -->


<h2>What is Orchestra?</h2>

<p>The chances are, you&rsquo;re probably reading this wondering what on Earth Orchestra actually is. In a nutshell, it&rsquo;s a purpose built Javascript framework for large scale applications. Harnessing the flexibility of <a href="http://marionettejs.com/">MarionetteJS</a> framework, it gives us the tools we need to enable us to implement some battle tested patterns for large scale Javascript applications.</p>

<p>It was built with the modularity and flexibility of the Bede platform in mind. Apps are split into smaller reuseable components: Chat, Tickets, Countdown etc for the Bingo Client, what this means is, should we decide we want a chat client in another game, we just include the orchestra-chat component and provide its config and &lsquo;it will just work&rsquo;. It has built in support for theming and localisation, allowing us to easily skin up new designs based on existing components. Our Bingo client is a great example of this in action. All of the bingo clients use the same core codebase, with a different theme and language file.</p>

<p>Even in its early days it was clear Orchestra was going to be a great fit for Bingo but now we have taken this a step further with a series of changes, and built our Slots Client using the same framework. The aim of this post is to explain the changes we made and the rational behind them.</p>

<h2>The battle of the Javascript Build Tools</h2>

<p>If I had a Â£ for every article I&rsquo;ve read with this heading as the title I&rsquo;d be an extremely rich man and would probably be writing this post from my yacht in the Bahamas. So, originally <a href="http://gruntjs.com">Grunt</a> was the build tool used for all our JS projects at Bede, it was amazing - everyone loved it, but, then something changed&hellip; <a href="http://gulpjs.com">Gulp</a> came along.</p>

<p>Now before you all think this is another case of simply jumping on a bandwagon, let me provide some justification for converting our build from Grunt to Gulp. We know that Gulp provides two main benefits:</p>

<ol>
<li>Code over configuration</li>
<li>Speed</li>
</ol>


<p>But what difference do these make to our apps? Code over configuration is something that is quite a difficult sell, however take a look at this snippet from our old Gruntfile:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
</pre></td><td class='code'><pre><code class='js'><span class='line'><span class="nx">less</span><span class="o">:</span> <span class="p">{</span>
</span><span class='line'>      <span class="nx">development</span><span class="o">:</span> <span class="p">{</span>
</span><span class='line'>      <span class="nx">options</span><span class="o">:</span> <span class="p">{</span>
</span><span class='line'>          <span class="nx">sourceMap</span><span class="o">:</span> <span class="kc">true</span><span class="p">,</span>
</span><span class='line'>          <span class="nx">ieCompat</span><span class="o">:</span> <span class="kc">true</span><span class="p">,</span>
</span><span class='line'>          <span class="nx">customFunctions</span><span class="o">:</span> <span class="p">{</span>
</span><span class='line'>              <span class="s1">&#39;assets-path&#39;</span><span class="o">:</span> <span class="kd">function</span> <span class="p">(</span><span class="nx">less</span><span class="p">,</span> <span class="nx">path</span><span class="p">)</span> <span class="p">{</span>
</span><span class='line'>                  <span class="k">return</span> <span class="s1">&#39;/assets/media/&#39;</span> <span class="o">+</span> <span class="nx">path</span><span class="p">.</span><span class="nx">value</span><span class="p">;</span>
</span><span class='line'>              <span class="p">}</span>
</span><span class='line'>          <span class="p">}</span>
</span><span class='line'>      <span class="p">},</span>
</span><span class='line'>      <span class="nx">files</span><span class="o">:</span> <span class="p">{</span>
</span><span class='line'>          <span class="s1">&#39;assets/css/bingostars/desktop.css&#39;</span><span class="o">:</span> <span class="p">[</span><span class="s1">&#39;assets/less/themes/bingostars/desktop/main.less&#39;</span><span class="p">],</span>
</span><span class='line'>          <span class="s1">&#39;assets/css/bingostars/mobile.css&#39;</span><span class="o">:</span> <span class="p">[</span><span class="s1">&#39;assets/less/themes/bingostars/mobile/main.less&#39;</span><span class="p">],</span>
</span><span class='line'>          <span class="s1">&#39;assets/css/healthbingo/desktop.css&#39;</span><span class="o">:</span> <span class="p">[</span><span class="s1">&#39;assets/less/themes/healthbingo/desktop/main.less&#39;</span><span class="p">],</span>
</span><span class='line'>          <span class="s1">&#39;assets/css/healthbingo/mobile.css&#39;</span><span class="o">:</span> <span class="p">[</span><span class="s1">&#39;assets/less/themes/healthbingo/mobile/main.less&#39;</span><span class="p">],</span>
</span><span class='line'>          <span class="s1">&#39;assets/css/stv/desktop.css&#39;</span><span class="o">:</span> <span class="p">[</span><span class="s1">&#39;assets/less/themes/stv/desktop/main.less&#39;</span><span class="p">],</span>
</span><span class='line'>          <span class="s1">&#39;assets/css/stv/mobile.css&#39;</span><span class="o">:</span> <span class="p">[</span><span class="s1">&#39;assets/less/themes/stv/mobile/main.less&#39;</span><span class="p">],</span>
</span><span class='line'>          <span class="s1">&#39;assets/css/betvictor/desktop.css&#39;</span><span class="o">:</span> <span class="p">[</span><span class="s1">&#39;assets/less/themes/betvictor/desktop/main.less&#39;</span><span class="p">],</span>
</span><span class='line'>          <span class="s1">&#39;assets/css/betvictor/mobile.css&#39;</span><span class="o">:</span> <span class="p">[</span><span class="s1">&#39;assets/less/themes/betvictor/mobile/main.less&#39;</span><span class="p">],</span>
</span><span class='line'>          <span class="s1">&#39;assets/css/lovebingo/desktop.css&#39;</span><span class="o">:</span> <span class="p">[</span><span class="s1">&#39;assets/less/themes/lovebingo/desktop/main.less&#39;</span><span class="p">],</span>
</span><span class='line'>          <span class="s1">&#39;assets/css/lovebingo/mobile.css&#39;</span><span class="o">:</span> <span class="p">[</span><span class="s1">&#39;assets/less/themes/lovebingo/mobile/main.less&#39;</span><span class="p">]</span>
</span><span class='line'>      <span class="p">}</span>
</span><span class='line'>      <span class="p">}</span>
</span><span class='line'><span class="p">}</span>
</span></code></pre></td></tr></table></div></figure>


<p>and compare it to:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
</pre></td><td class='code'><pre><code class='js'><span class='line'><span class="kd">var</span> <span class="nx">lessTaskNames</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;cleanCSS&#39;</span><span class="p">].</span><span class="nx">concat</span><span class="p">(</span><span class="nx">themeTaskGenerator</span><span class="p">(</span><span class="s1">&#39;less&#39;</span><span class="p">,</span> <span class="kd">function</span> <span class="p">(</span><span class="nx">theme</span><span class="p">,</span> <span class="nx">platform</span><span class="p">)</span> <span class="p">{</span>
</span><span class='line'>  <span class="k">return</span> <span class="nx">gulp</span><span class="p">.</span><span class="nx">src</span><span class="p">(</span><span class="s1">&#39;assets/less/themes/&#39;</span> <span class="o">+</span> <span class="nx">theme</span><span class="p">.</span><span class="nx">name</span> <span class="o">+</span> <span class="s1">&#39;/&#39;</span> <span class="o">+</span> <span class="nx">platform</span> <span class="o">+</span> <span class="s1">&#39;/main.less&#39;</span><span class="p">)</span>
</span><span class='line'>    <span class="p">.</span><span class="nx">pipe</span><span class="p">(</span><span class="nx">less</span><span class="p">({</span>
</span><span class='line'>      <span class="nx">modifyVars</span><span class="o">:</span> <span class="p">{</span>
</span><span class='line'>        <span class="s1">&#39;asset-path&#39;</span><span class="o">:</span> <span class="s1">&#39;&quot;/assets&quot;&#39;</span>
</span><span class='line'>      <span class="p">}</span>
</span><span class='line'>    <span class="p">}))</span>
</span><span class='line'>    <span class="p">.</span><span class="nx">pipe</span><span class="p">(</span><span class="nx">rename</span><span class="p">(</span><span class="nx">platform</span> <span class="o">+</span> <span class="s1">&#39;.css&#39;</span><span class="p">))</span>
</span><span class='line'>    <span class="p">.</span><span class="nx">pipe</span><span class="p">(</span><span class="nx">gulp</span><span class="p">.</span><span class="nx">dest</span><span class="p">(</span><span class="s1">&#39;assets/css/&#39;</span> <span class="o">+</span> <span class="nx">theme</span><span class="p">.</span><span class="nx">name</span> <span class="o">+</span> <span class="s1">&#39;/&#39;</span><span class="p">));</span>
</span><span class='line'><span class="p">}));</span>
</span></code></pre></td></tr></table></div></figure>


<p>From our new Gulp task, straight away you can see the reduced lines of code, but perhaps hidden in here is what I would consider a bigger benefit. Notice the list of output files in the Grunt config? This grows with every new theme, but because Gulp is code based, we can simply iterate over a <code>themes</code> array.</p>

<p>Something that is not such a difficult sell is the time shaved off our build task. Before Gulp we built 6 themes in a total time of 8 minutes, now, after the conversion, we are building 12 themes in 6 minutes - I think we can class that as a win. There are 2 main reasons for this speed benefit:
* Tasks are ran concurrently by default, whereas Grunt will only run tasks asynchronously.
* Gulp makes use of <code>pipe</code> which is native in node and most popular OS&rsquo;s. This means that whereas Grunt is required to create temporary files for its tasks, Gulp can pipe a file into its next task.</p>

<h2>The battle of the Javascript Module Loaders</h2>

<p>I&rsquo;m guessing you can see a theme appearing here, yet another well trodden path in the plethora of JavaScript blogs/articles is the comparison of the different module loaders available.
For me there are 3 main contenders:
* <a href="http://requirejs.org">RequireJS</a> which will load in AMD modules
* <a href="http://browserify.org">Browserify</a> which will load in CommonJS modules and
* <a href="http://webpack.github.io">Webpack</a> which will load anything and everything.</p>

<p>It should be noted that ES6 brings a new module pattern, which the community hopes will bring some unity. It is possible to start using these new ES6 features now with the help of <a href="http://babeljs.io/">Babel</a> which, will transpile ES6 modules to either AMD or CommonJS until they are widely available. I&rsquo;ve dabbled with Babel a bit and have some friends that work on the Babel project, it looks amazing, but we&rsquo;re not switching just yet! :smile:</p>

<p>Originally Orchestra was setup to build using AMD modules with the RequireJS tool, this was something that hindered us for a couple of reasons:</p>

<ul>
<li>The modules are loaded at the same time during development vs concatenated during a production build.</li>
<li>The build time was around 60 seconds per theme using RequireJS.</li>
</ul>


<p>Gulp is also unable to run these tasks concurrently, as that isn&rsquo;t supported by the RequireJS compiler. We needed to look at the alternatives. Browserify came up trumps - it allowed us to use the same module pattern across browser apps and Node.js apps and also solved the 2 problems I mentioned above: Your development version is the same as the production build, it compiles and provides sourcemaps (the overhead for the compile step when using <a href="https://github.com/substack/watchify">watchify</a> is milliseconds) and the build time per theme was reduced to 18 seconds - when you add the benefit of building all themes concurrently, its easy to see why this was a wise move for us!</p>

<p>That&rsquo;s it for part 1, in Part 2 I&rsquo;ll cover changes that were made as more apps began to use the Orchestra framework.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Rewrites and big bang deploys]]></title>
    <link href="http://engineering.bedegaming.com/blog/2015/01/12/rewrites-and-big-bang-deploys/"/>
    <updated>2015-01-12T12:37:14+00:00</updated>
    <id>http://engineering.bedegaming.com/blog/2015/01/12/rewrites-and-big-bang-deploys</id>
    <content type="html"><![CDATA[<p>Developers love to rewrite code:
* It&rsquo;s always more exciting to work on Greenfield development.
* The code you are working on was written by someone else and it is poorly written, hard to understand, or worse case, it doesnât do what the business requires.
* There are always shiny new things which developers want to use (reactive extensions, event sourcing etc. etc.) and it&rsquo;s not usually feasible to implement these in an existing service</p>

<!-- more -->


<p>(note: I am not advocating rewriting a service just for sake of some new technology or style).</p>

<p>Most of the time, the business will not let developers spend months rewriting a service on a whim. Why spend a small fortune in developer time refactoring, with no tangible business value added?</p>

<p>Here at Bede weâve been lucky (or possibly unlucky depending on your point of view) to have been given the chance to rewrite a few of our services from scratch. Weâve been able to show enough business benefit from doing it that the powers that be are willing to go a few months without any major feature development as they could see that short term pain will give long term gain.</p>

<p>Some of the reasons why we have gone for full rewrites over trying to just update the existing codebase:
* The existing service was written by an outsourced company, and wasnât well managed, resulting in the service not meeting the business requirements
* The existing service was a monolith. Pulling functionality out and making single responsibility services gives the ability to do a rewrite (especially as we have a much better understanding of business requirements)
* The existing service is not scalable enough for future needs</p>

<p>Now that we have a bit of experience in performing these rewrites, we have honed the method of how we integrate them into the platform without causing any detrimental affect to users. The original service rewrites would be deployed as a âbig bangâ release. It would immediately be released to all sites and players, and as good as our planning and testing might have been, when releasing code into the wild users always do things you donât expect. Worse case is you arenât even able to rollback the change and you perform firefighting to fix the issues as soon as possible.</p>

<p>We have two ways we can combat this to minimise impact to our players:
* Feature Switching
* Side by side running</p>

<p>Feature switching is a widely known topic and a lot of information about it is available across the internet. Within this blog post, I want to cover side by side running in a bit more depth, as I feel this has given us huge confidence in knowing how our new services will react when released into Production.</p>

<h3>Side By Side Running</h3>

<p><img class="center" src="http://engineering.bedegaming.com/images/tee.png" title="Request flow using Tee" alt="Request flow using Tee"></p>

<p>The diagram above shows the flow of traffic. The request Tee is a very small application sitting beside NGINX that takes the incoming request and duplicates it. The main request carries on to the existing service and the response that is returned is sent back upstream as per normal. The duplicated request is then asynchronously sent to the new version of the service, the response back from the new service is logged and then sent to /dev/null. This allows us to test the new service, with real production traffic, without impacting the existing service.</p>

<p>Sitting in front of the new service is a micro service (Mapper). Its job is to take the incoming request, map it to the contract of the new service before sending it to the new service. It then does the same for the response, mapping from new contract to old contract. Having this mapper service in place allows us to switch to the new service without having to update all upstream clients in one go. We can update them as and when the resource is available. Once all upstream clients are updated to communicate directly with the new service, we can delete the mapper service.</p>

<h3>Data Comparison</h3>

<p>The next benefit from doing side by side running is we can do data comparison between both services to make sure that data between services match. As the services within our platform all publish messages asynchronously, we created an application which consumes messages from both versions of the service and then compares the data. Any discrepancies are logged, which allows us to then find and resolve the issue.</p>

<p>We have used this method for our most recent service and it has given us the confidence to know that:
* The new service runs as expected and the data is valid
* The new service performs as expected (response times, memory / cpu usage etc)
* We can release the new service with no impact to upstream clients</p>

<p>Going forward, if we ever need to do another service rewrite, we will be using both feature switching and side by side running to give us a high degree of confidence that we wonât negatively impact the gaming experience for our players.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Bede gaming at NDC 2014]]></title>
    <link href="http://engineering.bedegaming.com/blog/2014/12/29/bede-gaming-at-ndc-2014/"/>
    <updated>2014-12-29T13:00:00+00:00</updated>
    <id>http://engineering.bedegaming.com/blog/2014/12/29/bede-gaming-at-ndc-2014</id>
    <content type="html"><![CDATA[<p>User identity and how we control access to systems has change a lot over the last decade or so, especially in the .net space.   At Bede we are looking to provide some significant updates to our authentication and access control services.  With those goals in in mind a couple members of our platform services team attended an Identity workshop at ndc London in December hosted by <a href="http://brockallen.com/">Brock Allen</a> and <a href="http://leastprivilege.com/">Dominick Baier</a> here are some of the topic areas we covered.</p>

<h2>First Some History..</h2>

<p>Back in 2002 with the first release of .net and ASP.net Identity and authentication in our applications basically boiled down to these two interfaces</p>

<pre><code>interface IIdentity
{
    bool IsAuthenticated {get;}
    string AuthentictaionType {get;}
    string Name {get;}
}

interace IPrinipal
{
    IIdentity Identity {get;}
    bool IsInRole(string roleName);
}   
</code></pre>

<p>This was how we secured our UI or applications using the couple of inbuilt authentication mechanisms provided by the .net framework e.g. Windows auth or Asp.net forms authentication.  These mechanism both handled validating user credentials, making identities (WindowsIdentity and FormIdentity respectively) and principals of the relevant type for us and popping them on the Thread.CurrentPrincipal.  Happy days problem solved move on.. Right?</p>

<p>Well we did have a huge disconnect between how we handled security in our applications and in our services.  On the front end we may have been using forms authentication while our service used something like <a href="http://en.wikipedia.org/wiki/WS-Security">wsSecurity</a>.</p>

<p>Then our application started getting more complicated, now our users may log into our web applications which in turn accesses back end services (which we also want to secure), but they can also use native client or smart phone applications.  These native apps may connect directly to our backend service or via public APIs.  We may also want third party applications to access subsets of our users data or allow users to log into our systems using there existing social media accounts.</p>

<p><img class="center" src="http://engineering.bedegaming.com/images/Typical" title="Typical Application authentication Scenario" alt="Typical Application authentication Scenario"></p>

<p>The solution is that we have a single place where we handle user authentication and manage user identities using a standard set of protocols that all our different clients can understand and that&rsquo;s where OpenID Connect comes in.</p>

<h2>OpenID Connect</h2>

<p>I bet your asking yourself is this not the problem that <a href="http://saml.xml.org/">SAML</a> was meant to solve (well maybe only some of you are asking yourself that). Yes and it works.  But you have to keep in mind</p>

<blockquote><p>&ldquo;SAML is the windows XP of Identity&rdquo; <a href="Craig">1</a></p></blockquote>

<ul>
<li>It was built 12 years ago</li>
<li>Its no longer developed</li>
<li>No body works on it</li>
<li>Its not the future</li>
</ul>


<p>Well then why can&rsquo;t we just use OAuth2 that popular now right well yes but OAuth2 is as I&rsquo;m sure we all know <a href="http://oauth.net/articles/authentication/">not an authentication protocol</a> its just a protocol for handling API access tokens. Lots of companies have tried to turn OAuth2 into an authentication protocol which is not a trivial problem.  The result of this is that we now have a lot of organisation with their own <a href="https://oauth.io/providers">flavor</a> of OAuth2.  Now you have facebook style OAuth and twitter style OAuth and we end up needing a client library for each. This trend of role your own authentication protocol has resulted in some fairly high profile hacks over the last few years.</p>

<p>So what&rsquo;s <a href="http://openid.net/connect/">OpenID Connect</a> well</p>

<blockquote><p>&ldquo;OpenID Connect 1.0 is a simple identity layer on top of the OAuth 2.0 protocol.&rdquo;</p></blockquote>

<p>What it does is to allow us to use OAuth2 for authentication by:</p>

<ul>
<li>Defines authentication protocol on top of OAuth2.
Where as OAuth2 is primarily used for API access token OpenID defines an identity token that can be used to identify a specific user.</li>
<li>Defines a standard <a href="http://self-issued.info/docs/draft-ietf-oauth-json-web-token.html">token types</a> which OAuth does not do, which makes it interoperable.</li>
<li>Defines standard cryptography that tell us how our token are protected no more role your own.</li>
<li>Defines how you validate a token</li>
<li>Defines work flows for native applications, browsers and servers.</li>
</ul>


<p>This means we can now do authentication and API access control in a single protocol.</p>

<h2>Identity Server</h2>

<p>Thinktecture <a href="https://github.com/thinktecture/Thinktecture.IdentityServer.v3">IdentityServer</a> is an open source OpenID Connect secure token server implementation. There are a host of none .net <a href="http://openid.net/developers/libraries/">implementations</a> as well. Secure token server have three major endpoints:</p>

<ul>
<li><strong>Authorise</strong> provide the pages the user is redirected to to allow them to login, it is basically responsible for rendering the UI</li>
<li><strong>Token</strong> deal with the identity and access control tokens</li>
<li><strong>User info</strong> give additional user detail like a profile</li>
</ul>


<h2>Flows</h2>

<p>There a different work flows supported by OpenID connect that allow you to authenticate different types of application.</p>

<ul>
<li><strong>Implicit Flow</strong> for native/browser/web apps user is redirected to login</li>
<li><strong>Authorisation Code Flow</strong> for server based applications</li>
<li><strong>Hybrid Flow</strong> for applications combining both</li>
</ul>


<p>The simplest example is probably the implicit flow.  A user wishes to log into a web application, the application redirects the user to our authorisation server with this query string</p>

<pre><code>GET /authorize
?client_id=app1
&amp;redirect_uri=https://app1.com/login
&amp;response_type=id_token
&amp;response_mode=form_post
&amp;scope=openid email
</code></pre>

<p>This identifies the application, where we want the user redirected to when they have authenticated, what response we are looking for in this case a token, how we want it back this time as a form post and the scope of information we want to know about the user here we are asking for their identity (<em>&ldquo;openid&rdquo;</em>) and their email.</p>

<p>The user will be asked to authenticate some how by our secure token server.  This could be username and password or using some third party social media site.  They may then be asked to give consent for the scopes we have requested and when that is complete a token containing the information requested will be posted back to us.</p>

<p>Using the same set of protocols and secure token server we came request access token for our API so that we can control access to our services.</p>

<h2>What in this token</h2>

<p>The token we get back from our client are <a href="http://jwt.io/">json web token</a>.  These token are a set of users claims represented as a json object that&rsquo;s base64 encoded and then digitally signed. It provides a URL safe way of transferring user identities in a format that can be validated by any client.</p>

<p>A claims is just a statement about the user:</p>

<blockquote><p>&ldquo;bob email is <a href="&#109;&#x61;&#x69;&#108;&#116;&#111;&#58;&#98;&#111;&#x62;&#64;&#x67;&#109;&#x61;&#105;&#108;&#46;&#99;&#111;&#109;">&#98;&#111;&#98;&#x40;&#x67;&#109;&#97;&#x69;&#x6c;&#46;&#99;&#x6f;&#109;</a> or bob is an admin&rdquo;</p></blockquote>

<p>they are usually represented as key value pairs e.g. &ldquo;email&rdquo;:&ldquo;<a href="&#109;&#97;&#105;&#108;&#116;&#111;&#58;&#x62;&#111;&#x62;&#x40;&#x67;&#x6d;&#x61;&#105;&#x6c;&#x2e;&#99;&#111;&#x6d;">&#98;&#x6f;&#x62;&#x40;&#103;&#109;&#97;&#105;&#108;&#x2e;&#99;&#111;&#x6d;</a>&rdquo;.</p>

<p>The claims in the json web token are part of user the identity information that we have request and is determined by the scope we asked for.</p>

<p><strong>Example claims</strong></p>

<pre><code>{
  "sub": 1234567890,
  "name": "John Doe",
  "email": "Johndoe@email.com"    
}
</code></pre>

<p>&ldquo;sub&rdquo; in the above example is the unique identifier for a specific user this will be provided when we request the openid scope.</p>

<h2>What this mean for my application</h2>

<p>This all mean we now have a set of protocols that allow us to manage user identity and access control for a range of application and client types from one single secure token server.</p>

<p>In the .net space we still have the two interfaces we are familiar with IIdentity and IPrincipal but now we can inherit from a common set of claims based implementation.</p>

<pre><code>class ClaimsIdentity : IIdentity
{
    IEnumerable&lt;Claim&gt; Claim {get;}
}

class ClaimsPrincipal : IPrincipal
{
    ReadOnlyCollection&lt;ClaimsIdentity&gt; Identities {get;}
}   
</code></pre>

<p>All our users claims are provided in the openid token given to us by our secure token server.</p>

<p>References</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Bede Gaming at ÂµCon 2014]]></title>
    <link href="http://engineering.bedegaming.com/blog/2014/12/10/bede-gaming-at-ucon-2014/"/>
    <updated>2014-12-10T14:15:55+00:00</updated>
    <id>http://engineering.bedegaming.com/blog/2014/12/10/bede-gaming-at-ucon-2014</id>
    <content type="html"><![CDATA[<p>Microservices have gained more and more popularity in the software community during the past couple of years, up to the point that SkillsMatter has dedicated them an entire convention in London, ÂµCon. I was lucky enough to participate  and here are some of the ideas that have been discussed.<!-- more --></p>

<h2>What is a micro service?</h2>

<p>Itâs always a good idea to start with a clear definition, so here is what <a href="http://en.wikipedia.org/wiki/Microservices">Wikipedia</a> has to say on the matter:</p>

<blockquote><p>&ldquo;Microservices is a software architecture design pattern, in which complex applications are composed of small, independent processes communicating with each other using language-agnostic APIs. These services are small, highly decoupled and focus on doing a small task.&rdquo;</p></blockquote>

<p>This seems appropriate, but leaves some open questions: how small a microservices should actually be? and what about the tasks? Somebody answers this questions by saying that a microservice shouldnât be more than one hundred lines of code. Unfortunately, this looks like quite a silly rule of thumb. The best way to answer both questions is by thinking of microservices as Object Orientation applied to software design. A microservice becomes the counterpart of a class, and the single responsibility principle defines what small means: enough logic to be able to perform a single task, and no more than that.</p>

<h2>Whatâs all the fuss about?</h2>

<p>In the late â60, Conway made an interesting sociological observation:</p>

<blockquote><p>&ldquo;organizations which design systems &hellip; are constrained to produce designs which are copies of the communication structures of these organizations&rdquo; [1]</p></blockquote>

<p>This allows us identify a relation between Agile principles and Microservices: the principles have changed how software is built and how the teams interact, and, following from Conwayâs law, this has changed how systems are designed. In some way, we could even go to the extent of saying that microservices are the natural expression of an Agile software development.</p>

<p>As much as the sociological explanation can be interesting, microservices have also several technical  benefits:</p>

<ol>
<li>Scalability : the only way you can scale a monolith is running several copies of the entire service. With a microservices approach, we can chose the which ones we need multiple instances of.</li>
<li>Easy to understand and maintain : being small and covering a single task, a microservice is much easier to understand and to maintain than a single, huge piece of software.</li>
<li>Easy to deploy : to bring even the smallest change to a monolith service in production, means deploy the entirety of it, with possible downtime and all the related problems. With microservices instead, the deployment of a single one of them can be done without bringing the entire infrastructure down.</li>
<li>Failure resilient : a failure in a monolithic application, means a failure of the entire service. On the other hand, the failure of a single microservice doesnât reflect into a paralysis of the entire infrastructure.</li>
<li>Loosely coupled</li>
</ol>


<h2>Whatâs the catch?</h2>

<p>Unfortunately microservices are not the panacea of all evils. They indeed help removing the complexity from the service layer, but they push it down to the network layer. The two main problems that arise when dealing with a microservices infrastructure are discovery and handling of failures.</p>

<h3>Discovery</h3>

<p>With a monolith, everything sits in one place, so resources location doesnât really pose any issue. This is becomes a problem when you have hundreds of microservices that need to communicate with each other.</p>

<p>The naive solution is to use a different url per service, and pass those in from the outside: this means that every time a single microservice address changes, all its consumers need to be updated. Things get even more complicated if we have several instances of a microservice that we want to consume: what if the one we know the address of is offline, but we have some other up and running?
The standard solution to this problem is a discovery micro service, that points us to the service we are asking for. Furthermore, to help other developers explore the service, a new standard has been suggested: adding a  <code>/disco</code> endpoint to each microservice, listing the available endpoints and a short description of each one of them. [2]s</p>

<h3>Handling Failures</h3>

<p>Being resilient to failures is a good property for a system, but it raises the problem of identifying when one of the many microservices shuts down, and not hammering it until itâs restarted. Both problems can be solved using the circuit breaker pattern, explored in detail <a href="http://martinfowler.com/bliki/CircuitBreaker.html">in this blog post</a> by Martin Fowler.</p>

<h2>Final thoughts</h2>

<p>Microservices are not the final goal: as developers, that remains building software that satisfies the business requirements. But they are a very powerful tool we have in our arsenal, and that can help us reaching the goal, and building overall better software.</p>

<p>References</p>

<p>[1] : Conway, Melvin E. (April 1968), &ldquo;<a href="http://www.melconway.com/research/committees.html">How do Committees Invent?</a>&rdquo;, <a href="http://en.wikipedia.org/wiki/Datamation">Datamation</a> 14</p>

<p>[2] : Greg Young, âThe future of Microservicesâ, ÂµCon 2014</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Adding InstancePerRequest to Non-Web Applications]]></title>
    <link href="http://engineering.bedegaming.com/blog/2014/12/09/Adding-InstancePerRequest-to-Non-Web-Apps/"/>
    <updated>2014-12-09T16:02:00+00:00</updated>
    <id>http://engineering.bedegaming.com/blog/2014/12/09/Adding-InstancePerRequest-to-Non-Web-Apps</id>
    <content type="html"><![CDATA[<p>Here at Bede we use <a href="http://autofac.org/">Autofac</a> a lot. It&rsquo;s an excellent <a href="http://en.wikipedia.org/wiki/Inversion_of_control">IoC</a> container which allows us to create well structured code focused on interfaces rather than implementations. If you are not familiar with IoC, or it&rsquo;s most commonly used form of <a href="http://en.wikipedia.org/wiki/Dependency_injection">Dependency Injection</a>, I&rsquo;d suggest the essential (.NET) reading of <a href="http://www.amazon.co.uk/Dependency-Injection-NET-Mark-Seemann/dp/1935182501">Dependency Injection in .NET</a> as a primer.</p>

<p>A typical basic example would be at the beginning of our application (called the &ldquo;composition root&rdquo;) to do something like</p>

<pre><code>var builder = new ContainerBuilder();
builder.RegisterType&lt;MyWorkService&gt;().As&lt;IWorkService&gt;();
_container = builder.Build();
</code></pre>

<p>This says that any time someone asks for an <code>IWorkService</code> that they should have that satisfied with a <code>MyWorkService</code> implementation. This leaves you free to write code like</p>

<pre><code>public class MyController : ApiController
{
    private readonly IWorkService _workService;

    public MyController(IWorkService workService)
    {
        _workService  = workService;
    }
}
</code></pre>

<p>&hellip;and not be worried about where that <code>IWorkService</code> is going to come from. It&rsquo;s a critical pattern for clean, re-usable, testable code, and one we use consistently throughout the business in all our apps.</p>

<h2>IoC Containers and the Web - Instance Per Request</h2>

<p>IoC containers like Autofac come ready prepared to hook into web and API applications (my example controller above would fail to run if I had not hooked up Autofac). We find ourselves naturally starting to depend upon Autofacs built in help for scoping dependencies. For example if we changed the <code>IWorkService</code> registration above to</p>

<pre><code>var builder = new ContainerBuilder();
builder.RegisterType&lt;MyWorkService&gt;().As&lt;IWorkService&gt;().InstancePerRequest();
_container = builder.Build();
</code></pre>

<p>We actually change <em>when</em> a new <code>MyWorkService</code> is constructed. Before it would be <em>any time</em> a contructor asked for an <code>IWorkService</code>. Now it is only once for each web request. We could go a step further and do</p>

<pre><code>var builder = new ContainerBuilder();
builder.RegisterType&lt;MyWorkService&gt;().As&lt;IWorkService&gt;().SingleInstance();
_container = builder.Build();
</code></pre>

<p>&hellip;and now we will only ever construct one object and hand it out every time we are asked to satisfy the <code>IWorkService</code> class.</p>

<p>These techniques are excellent - because it allows us to ensure that objects that are &ldquo;costly&rdquo; to instantiate are only constructed when absolutely needed, and further, items that are created once &ldquo;per request&rdquo; in a web application can essentially persist context of that request within the service (username, request parameters, caller IP Address, etc.)</p>

<p>We leverage the &ldquo;InstancePerRequest&rdquo; for several contextual services, as it means that you can assign context values to service properties, rather than as parameters of its methods. For example:</p>

<pre><code>public MyController(IWorkService workService)
{
    _workService  = workService;
}

public HttpResponseMessage Update(MyRequest request)
{
    List&lt;string&gt; values;
    Request.Headers.TryGetValues("userAppKey", out values)
    _workService.AppKey = values[0];

    ...

    _workService.DoStuff(request);
    _workService.DoMoreStuff();
}
</code></pre>

<p>This is great, as we now don&rsquo;t have to add the &ldquo;userAppKey&rdquo; to each and every method signature.</p>

<h2>Instance Per Request for non-web applications</h2>

<p>It&rsquo;s great that Autofac has such rich built in support for ASP.NET MVC and WebApi applications, but sometimes you are working other forms of application that appear to meet the same pattern. A classic example of this is any &ldquo;message processing application&rdquo; - for example, an azure worker role that listens for Azure Service Bus messages, but it could be any message consumer (including just listening on a socket for data). In such cases your context is the message that arrives, and in reality this is no different to an Http request - its just a message format we have all gotten really used to.</p>

<p>So how do we deal with providing an &ldquo;Instance Per Request&rdquo; in these scenarios? Thankfully Autofac is fully designed to help us out here.</p>

<h2>Scoping our Request</h2>

<p>Autofac allows you to create a <code>scope</code> at any time in your code. If you register your dependencies correctly, using <code>InstancePerLifetimeScope</code>, Autofac will construct a new object inside that scope if none already exists</p>

<pre><code>builder.RegisterType&lt;MyWorkService&gt;().As&lt;IWorkService&gt;().InstancePerLifetimeScope();
</code></pre>

<p>We can make our own scope as follows:</p>

<pre><code>static void Main(string[] args)
{
    //Composition Root
    var builder = new ContainerBuilder();
    builder.RegisterType&lt;MyWorkService&gt;().As&lt;IWorkService&gt;().InstancePerLifetimeScope();
    builder.RegisterType&lt;MyOneOfAKindService&gt;().As&lt;IOneOfAKindService&gt;().InstancePerLifetimeScope();
    _container = builder.Build();

    var rootScope = _container.BeginLifetimeScope();
    for (int i = 0; i &lt; 5; i++)
    {
        var oneOfAKind = rootScope.Resolve&lt;IOneOfAKindService&gt;();

        using (var scope = _container.BeginLifetimeScope()) 
        {
            Console.WriteLine("Handing Event " + i);

            // we will get a one and only one instance for each iteration of the for loop, no matter
            //how many times we call scope.Resolve&lt;IWorkService&gt;()
            HandledEvent(oneOfAKind, scope.Resolve&lt;IWorkService&gt;()); 
        }
    }

    Console.ReadKey();
}
</code></pre>

<p>Here we use the <code>Resolve</code> method on a scope to get hold of our implementation. Autofac checks how you registered the implementation against the interface, and decides when to give you a new instance or a current one. We can make this more specific, and basically create our own &ldquo;InstancePerRequest&rdquo; registration with:</p>

<pre><code>builder.RegisterType&lt;MessageContext&gt;().As&lt;IMessageContext&gt;().InstancePerLifetimeScope("MessageRequest");

using (var scope = _container.BeginLifetimeScope("MessageRequest")) 
{
    //...
    var context = scope.Resolve&lt;IMessageContext&gt;();
    var message = GetRawMessageFromBus();
    MapMessageToContext(message, context);

    //assume that this is overridden, and/or leads to construction of an object that takes 
    //an IMessageContext interface
    HandleMessage(context); 
}
</code></pre>

<p>The code above is fairly basic, but proves the point. Revise it and package it up a little and you can a context aware framework that works very nicely with Autofac.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Waste In Software]]></title>
    <link href="http://engineering.bedegaming.com/blog/2014/12/01/waste-in-software/"/>
    <updated>2014-12-01T16:49:00+00:00</updated>
    <id>http://engineering.bedegaming.com/blog/2014/12/01/waste-in-software</id>
    <content type="html"><![CDATA[<p>One of several interesting areas to come out of our tour of Nissan in Sunderland today was how they classify wastage into seven different categories</p>

<ol>
<li><strong>Over-Production</strong>: Making more cars than you need is expensive. you used more people, and now you have to store them somewhere. In the past large car companies might be paying a farmer for use of fields to store the vehicles in until they could be sold. The long term storage is doubly damaging, as rodents tend to love making their homes in the vehicles</li>
<li><strong>Inventory or Stock</strong>: Again, <!-- more --> having more parts in inventory than required takes up storage space, and you may already have paid for the materials. At best, you&rsquo;ve paid too soon, at worst those items may never be required.</li>
<li><strong>Transportation</strong>: This is a big one for manufacturing. Any time you move anything anywhere it costs you money. This could be between factories, where fuel costs add up and traffic delays can ruin your scheduling, or it could be within the factory, where a worker has to cover a part of the floor to get a tool or component. Nissan (and Toyota) take this very seriously. As manufacturing has predictable material costs and value of product, they can actually put a cost &ldquo;per worker footstep&rdquo; to every action within the business. Saving 6-10 footsteps for a process could save thousands of pounds per year</li>
<li><strong>Non Value Adding</strong>: For example legal or safety processes. These things are generally mandatory</li>
<li><strong>Idle Time</strong>: Time waiting for the next item to be delivered to at your workstation is time that does not add value. In the world of manufacturing this is more opportunity to reduce the number of people required for a workstation</li>
<li><strong>Operator Motions</strong>: Bending over to pick stuff up, twisting in under a hood, clambering into the cabin to screw in bolts, or two people working on achieving a single task. Nissan have some really awesome solutions to these problems, for example; instead of scrambling into the cabin to tighten bolts (and probably injure yourself on all the various spiky and sharp edges), they now slide into the cabin on a machine mounted seat that can swivel in and out as the car moves down the line</li>
</ol>


<p><img class="center" src="http://engineering.bedegaming.com/images/nissan-chair.jpg" title="Nissan sliding chair device" alt="Nissan sliding chair device"></p>

<ol>
<li><strong>Poor Quality</strong>: Obvious enough, and one most people are familiar with, but having to fix an item already through the production line is firstly rework, and secondly slower than if it was originally done correctly. Each quality issue is one less car that can go out the factory doors that day. I do find it interesting that its at the bottom of the list for Nissan. They&rsquo;ve obviously removed a lot of the occurrences of this to the point where it is maybe not their most pressing problem</li>
</ol>


<p>I&rsquo;ve been thinking on the differences between what we (software developers) do, and what Nissan (manufacturing) does. Off-the-cuff comments after the tour among colleagues suggested that yes, we probably suffered from at least three of these, but because we are writing software we cannot overproduce, and we don&rsquo;t hold inventory or stock.</p>

<p>On closer reflection though, I think that there are clear parallels between the two industries. Here is my take on an equivalent &ldquo;seven wastes&rdquo;</p>

<ol>
<li><strong>Over-Production</strong>: The feature that was implemented but not asked for, the feature that was demanded but never used, and&hellip;here&rsquo;s the kicker; over-engineering. Some examples are &ldquo;the performance improvement that was not required&rdquo; and &ldquo;the N-tier-highly-scalable-plugin-architecture-driven-workflow-system for the five person internal admin application&rdquo;. These are all examples of work being done that did not result in monetary value being added to the business. How many times have you heard &ldquo;its a cool feature all right, no one <em>uses</em> it, but it is cool.</li>
<li><p><strong>Inventory</strong>: We don&rsquo;t have inventory though, right? Sure we do. Partially completed features on pause due to something else being today&rsquo;s most pressing concern, half-migrated database systems, licenses for products never used. It&rsquo;s all virtual &ldquo;stock&rdquo; or <em>work in progress</em>. Someone has produced a part of a thing, and that thing has not yet been put together.</p>

<blockquote><p><em>&ldquo;Work in progress is a real killer&rdquo;</em></p>

<p>From Nissan&rsquo;s talk on manufacturing wastage</p></blockquote></li>
<li><p><strong>Transportation</strong>:This is the one that I had to think about longest and hardest. In the virtual world we don&rsquo;t really &ldquo;transport&rdquo; goods, and generally data-transfer costs are pretty negligible. True, if you are moving data between two locations that have really slow connections, and the connections are flaky, but this is not really a fair comparison with the manufacturing version. Transportation is about moving between two factories or workstations, our example on reliable connections above would more be akin to reliable power and conveyor belts. Instead, perhaps the time taken to deploy and prepare environments for QA might be a better example, as we are moving between the software equivalents of workstations - states of a work item. If deployment takes a long time, or worse, you have to spend time manually reseting your QA environment to a &ldquo;known good&rdquo;, then this is time when you are trying to move the item between &ldquo;in development&rdquo; and &ldquo;in QA&rdquo;. Its neither one nor the other. We would say it was &ldquo;transitioning&rdquo;.</p></li>
<li><strong>Non-value adding</strong>: The same comments on legal processes apply equally to software development. Data protection/privacy and PCI compliance being common ones. In the online gaming world we tend to have things like &ldquo;Know your customer&rdquo; (understanding if multiple user accounts are really on real person) that we need to do to be good netizens, but don&rsquo;t directly add to the bottom line. Of course, in many if not all &ldquo;non-value adding&rdquo; requirements, they generally do actually add a form of value, called <em>goodwill</em>. If you are seen to a fair player, good safety record or whatever, then people have a tendency to put their trust in you, rather than your competitor. Its very hard to measure the direct impact. You could also argue that legal requirements are worth the <em>entire value of your company</em> if someone is going to shut you down if you don&rsquo;t comply ;)</li>
<li><strong>Idle Time</strong>: It&rsquo;s not too hard to see this one. Team city build times. Deployment times between environments. How long <em>does</em> your machine take to load visual studio anyway ;). What about waiting for a firewall change to be put in place by ops for a new service you&rsquo;ve just written and want to deploy to your dev environment for the first time? Are you going to switch task for the five minutes it takes (or 20 if you are still deploying Azure Cloud Services). A lot of this time is just dead, because your choices are to continue to focus on the task at hand (i.e. do nothing for x minutes) or to context-switch to something else. Since a lot of intellectual tasks can take fifteen plus minutes to get into, and fifteen to get out of again, you&rsquo;re not going to do too well here! (Also, you&rsquo;ve just introduced new <em>work in progress</em>).</li>
<li><strong>Operator Motions</strong>: Manually refactoring all the namespaces of classes in a folder, adding &ldquo;begin method&rdquo; and &ldquo;end method&rdquo; logging to classes, opening the azure portal and clicking the &ldquo;connect&rdquo; option to download an RDP file, before opening a password store to find the unique username/password details for that machine, these are all examples of &ldquo;motions&rdquo; that waste potentially significant amounts of time, repeatedly.</li>
<li><strong>Poor Quality</strong>: Definitely a distinct bane of the current software industry, manufacturing definitely has us there. Again, the double whammy of redoing something already done, and the fact that you have to context switch to do it/might need to work outside your normal delivery process makes this a bitter pill</li>
</ol>


<p>So there you go! Perhaps software engineering is not that different from manufacturing. If these wastage points can all be found to have equivalents, then maybe its far too soon to say &ldquo;but manufacturing is different because of all the predictability&rdquo;. Perhaps its just because we aren&rsquo;t very good at predicting yet&hellip;</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Bede Gaming Puppet Module for Redis]]></title>
    <link href="http://engineering.bedegaming.com/blog/2014/11/24/puppet-redis-module/"/>
    <updated>2014-11-24T16:30:00+00:00</updated>
    <id>http://engineering.bedegaming.com/blog/2014/11/24/puppet-redis-module</id>
    <content type="html"><![CDATA[<p>As of last week we&rsquo;ve created and released a Puppet Module for Redis.  While there are other Redis modules available on GitHub and the Forge, we think a lot of them are either overly complex or outdated in their design and methods.  Many of them also install from source packages, which we don&rsquo;t like.</p>

<!-- more -->


<p>We think our module is a bit better:</p>

<ul>
<li>Simple, clean layout</li>
<li>Offers single entry point (the &lsquo;::redis&rsquo; class)</li>
<li>Provides a full set of sane defaults</li>
<li>Provides for all configuration options found in the redis.conf file</li>
<li>Does all the basic installation, configuration and management you&rsquo;d expect</li>
</ul>


<p>One of the other major reasons for our own module was our desire to not use Redis that came from source packages.  We use CentOS for the Linux portion of our platform, and are pretty religious about only installing from RPM&rsquo;s.  This module expects that there will be a Redis RPM package available somewhere within the yum repos you&rsquo;ve made available on your systems, which we feel is good design, as it leaves it up to you to implement that package source.  That&rsquo;s not the job of a Redis module.</p>

<p>Currently the Redis module is not on the Forge, but probably will be in the near future.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Bede Gaming Puppet Module for FoundationDB]]></title>
    <link href="http://engineering.bedegaming.com/blog/2014/11/18/puppet-foundationdb-module/"/>
    <updated>2014-11-18T16:30:00+00:00</updated>
    <id>http://engineering.bedegaming.com/blog/2014/11/18/puppet-foundationdb-module</id>
    <content type="html"><![CDATA[<p>Here at Bede we&rsquo;ve been using <a href="https://foundationdb.com/">FoundationDB</a> for some time, and are basically in love with it.  Fully distributed, ACID compliant transactions?  Yes please.  It&rsquo;s fast, it scales, it&rsquo;s reliable and redundant.  From an operations persons point of view it&rsquo;s simply sexy.</p>

<!-- more -->


<p>However, it is a relatively new technology, with a small but growing community.  That means that the ecosystem surrounding FDB is not quite as extensive as many of the other, longer lived persistence technologies.  Therefore there was no Puppet modules available to manage installation and configuration, so we had to write our own.</p>

<p>The <a href="https://github.com/BedeGaming/puppet-foundationdb">module</a> can manage installation, configuration, upgrading, etc.  All the usual bits&#8217;n&#8217;bobs you&rsquo;d expect a Puppet module to manage.  This does come with one caveat however:  it doesn&rsquo;t currently manage FDB cluster membership, due to the way FDB itself manages membership.  We&rsquo;re still exploring ways to add at least some amount of membership management into the module, and of course if anyone wants to contribute towards the module, feel free to fork and issue PR&rsquo;s.</p>

<p>The FoundationDB module can be found on the <a href="https://forge.puppetlabs.com/bedegaming/foundationdb">Forge</a>.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Bede Gaming Sponsors Biggest Hackathon in the North East]]></title>
    <link href="http://engineering.bedegaming.com/blog/2014/11/13/bede-sponsors-hackne/"/>
    <updated>2014-11-13T09:20:08+00:00</updated>
    <id>http://engineering.bedegaming.com/blog/2014/11/13/bede-sponsors-hackne</id>
    <content type="html"><![CDATA[<p>Billed as <a href="http://http://www.chroniclelive.co.uk/news/local-news/newcastle-set-north-easts-biggest-8052017">âThe biggest public hackathon ever held in the North Eastâ</a>, <a href="http://hackne.com">Hack NE</a>, for Bede, was an ideal opportunity to get our name known in the community.  With a largely student based attendee list, people had come from as far away as London to compete. With free t-shirts, face cloths, breath mints, wet wipes and swag bags, Bede&rsquo;s branded 8Gig USB sticks looked a good addition for those brave enough to come talk to us.</p>

<!-- more -->


<p>As co-sponsor, we set a challenge for the competing teams. Bede supplied a Kafka service to publish a real-time event stream of messages about deposits, withdrawals and winners for a mock gaming website. We challenged the Hackers to consume the messages and create something beautiful.</p>

<h3>Day 1, 9AM</h3>

<p>With the hackers seated in the halls of the Hancock museum, and ready to start, Bede MD Dan Smyth took to the podium to deliver an inspired speech about Bede and an introduction to our challenge. This was followed by 5 other sponsors. All told there were 5 prizes on offer, including the actual Hack NE overall champion.</p>

<p>Representing the tech side of Bede were: Mark Radford, Daniel Lackenby, Amila Prabandhika, Richard Thompson and Anton Jidkov, with Andy Thompson fielding questions about the company and careers opportunities. As the teams started work on whose services they would use, a few nervous hackers approached us and asked for more details on the service. It seemed that with a prize of Â£100 Amazon vouchers per team member, we had their interest.</p>

<p>By the time the Bede techies had retired for the day, three teams of hackers had incorporated our challenge into their projects, using Java and Ruby Kafka clients respectively to consume the data we had made available. Just from walking around the room and assisting where we could to get teams up and running with the data there was no question that some cool hacks were being undertaken using Bedeâs service as well as teams that had gone for their own ideas. We left them to their night of caffeine and code.</p>

<h3>Day 2, 7AM</h3>

<p>The room of hackers had been whittled down to a hardy few, breakfast was being served.
A slight panic had arisen at 3am, the Kafka service has stopped responding to requestsâ¦
A restart of the service had it working again so all was not lost for the teams that had pushed through.
Bede USB Sticks all gone, loads of SendGrid T-shirts left.</p>

<h3>Day 2 9AM</h3>

<p>Presentations were to be done in the Newcastle Students Union.
In total, 8 teams presented with 6 having a finished, working product.
Each sponsor gets to award their prize to the team they liked best with the overall prize being awarded by MLH.
The best presentations were:
Stockcruiser - a fantastic visual representation of organically created cars that ran along a track. The track was generated by using data from the Bloomberg API with the car jumping based on Bede&rsquo;s winners feed and power ups appearing with deposits.</p>

<p><img class="center" src="http://engineering.bedegaming.com/images/hack-stockcruiser.jpg" title="Stock Cruiser Presentation" alt="Stock Cruiser Presentation"></p>

<p>Metro Apologises - Using the Metro information boards as a theme, they showed the Winners there and took the Bloomberg stocks figures to show a cartoon metro train derailing itself (or other reactions depending on the size of the figures).
BloomBedeGridMachine - Using an Arduino board and an LED Ticker Grid, The Bede winners ticked across the Grid and then showed a graph of the winning amounts over a time period. Then, a click of a remote control and the Feed showed Stock prices from the Bloomberg API.
<img class="center" src="http://engineering.bedegaming.com/images/hack-crablab.jpg" title="Crablab present BloomBedeGridMachine" alt="Crablab present BloomBedeGridMachine"></p>

<p>A quick conflab with the other sponsors and we each decided our winners. Bede awarded its prize to the BloomBedeGridMachine.</p>

<p><img class="center" src="http://engineering.bedegaming.com/images/hack-handshake.jpg" title="Bede Congratulate the Winners" alt="Bede Congratulate the Winners"></p>

<p>Despite presenting on a refreshments trolley, they had worked extremely well as a team, each taking a single task on with one team member linking all the parts together and project managing.
One team member is quoted as saying âThat Kafka software is awful to integrate withâ.</p>

<p>We had a lot of enquires about Bede as a prospective employer and if we take summer/year long interns. All in all, Bede has projected a positive message to the local tech community and looks forward to hosting more hackathons in the future.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[CD in action at Nissan Sunderland]]></title>
    <link href="http://engineering.bedegaming.com/blog/2014/11/06/cd-in-action-at-nissan-sunderland/"/>
    <updated>2014-11-06T12:54:14+00:00</updated>
    <id>http://engineering.bedegaming.com/blog/2014/11/06/cd-in-action-at-nissan-sunderland</id>
    <content type="html"><![CDATA[<p>The Nissan UK car plant at Sunderland produces almost as many cars every year as Italyâs entire automative industry. Itâs a mammoth site.  Each of the four production lines in this factory is capable of producing one car every minute, continuously. As in 24x7x365. True continuous delivery into production. I was lucky enough to be invited on a factory tour by the good people at the <a href="http://www.entrepreneursforum.net">entrepreneurs forum</a> recently. It was fascinating to see how Nissan have engineered every aspect of production to minimise waste and keep the line flowing. At Bede I&rsquo;ve spent a lot of my time trying to enable agile teams to deliver high quality software into production as fast as possible, so after the factory tour my mind was left reeling with comparisons between Nissan and Bede&rsquo;s approaches to Continuous Delivery.</p>

<p><img class="center" src="http://engineering.bedegaming.com/images/nissan-plant.jpg" title="Aerial view of Nissan UK plant at Sunderland" alt="Aerial view of Nissan UK plant at Sunderland">
<em>Source: <a href="http://www.themanufacturer.com/articles/nissan-smashes-uk-output-record-at-sunderland-plant/">http://themanufacturer.com</a></em></p>

<!-- more -->


<p>I&rsquo;ve visited a few factories in a previous life, but I&rsquo;ve never visited a car production line: it&rsquo;s quite something to behold. Chassis are on a continuously moving conveyer, separated by a few feet, and move along the factory floor passing a succession of workstations.  The production conveyer moves at a constant speed - every work station has 60 seconds to perform its assigned tasks.  Some workstations have a single task to perform, others fit multiple parts to the chassis. Larger jobs are split up between multiple work stations.  Everything possible is done to ease the job of the fitter.  This is done by minimising the physical movements required, minimising risk of a line stoppage, reducing waste and maximising the amount of useful work that can be done in 60 seconds.</p>

<p><img class="center" src="http://engineering.bedegaming.com/images/nissan-line.jpg" title="Nissan UK Qashqai production line" alt="Nissan UK Qashqai production line">
<em>Source: <a href="http://petrolblog.com/2012/05/rising-sunderland-a-british-success-story/">http://petrolblog.com/</a></em></p>

<p>Some rambling thoughts from the visit:</p>

<h3>Shared Vision</h3>

<p>Nissan are big on shared vision. Our tour guides, both ex Nissan employees, bleed Nissan. It was clear that they understood Nissan&rsquo;s vision and were proud to be associated with them. Nissan work hard to install a sense of shared values in their staff. Information radiators are everyone throughput the plant - both static and display screens.  The primary metric on the shop floor is efficiency - which seems to be the number of cars rolling off the line compared to target.  On the day I visited the plant was running at 108% efficiency. A similar metric for Bede might be the number of successful production deployments achieved in a given time period.  Right now I&rsquo;d estimate we push out 5-10 builds into production each week.</p>

<p>Despite employees showing a strong sense of Nissan pride, they know that efficiency relative to other plants will determine whether Sunderland receives future car models for manufacture, implying expansion and job security. This presents an interesting dichotomy - staff are passionate about Nissan as a brand, but have a local basis - they are in direct competition with other global Nissan car plants to ensure long term security.  Interestingly, Bede has 3 software development offices - Newcastle, London and Sofia.  We&rsquo;ve worked hard to break down inter office rivalries, and have many product teams that span at least one office boundary.  In this sense, Bede&rsquo;s world of bits frees it from Nissan&rsquo;s physical limitations in terms of delivery across a distributed estate.</p>

<h3>Continuous, relentless delivery to production</h3>

<p>Production workers understand that nothing can be allowed to stop the line. It&rsquo;s the shared responsibility of every employee to do whatever it takes to minimise downtime.  I heard that stoppages cost something like Â£10,000 per minute. This has two separate parallels in the software world.  Firstly, the production effort - keeping the build green, ensuring that only quality builds are deployed into environments. Through careful application of continuous integration, testing and sandbox deployments, especially with Bede&rsquo;s SOA, we strive to minimise the amount of time that the line is down (e.g. environments are broken). We&rsquo;ve recently added an isolated automation testing environment at the head of our CI pipeline, to perform smoke tests on builds before automatically deploying into our first visible development environment. This increases the overall stability of the development environment at the cost of adding some time between commits being available for developer testing. We opted to make this trade off to focus on stability, since multiple product teams shares a common development environment.</p>

<p><img class="center" src="http://engineering.bedegaming.com/images/octopus-dashboard.png" title="Continuous Integration Dashboard" alt="Continuous Integration Dashboard"></p>

<p>Secondly, uptime in production - Bede manages the production environments for its clients, so relentless monitoring of servers and applications is required to keep the status green and exceed stated SLA uptimes. Of course Nissan&rsquo;s relationship with their product continues long after delivery too, though a most shared approach for managing that client relationship exists in the form of dealerships.</p>

<p><img class="center" src="http://engineering.bedegaming.com/images/ops-nr-dashboard.jpg" title="Environment Monitoring" alt="Environment Monitoring"></p>

<h3>QA</h3>

<p>Quality Assurance at the Nissan plant boils down to accountability.  As each chassis passes a workstation, the fitter stamps a card (yes, a physical piece of paper) with their own personalised stamp. In this way they&rsquo;re taking direct responsibility for the quality of the work they are performing. The card forms part of the permanent history of the car, it is never destroyed. As a result, fitters must take responsibility for their work.  Dedicated Quality Assurance staff do exist in the plant, but their job exists to catch unforeseen errors. I like the idea of producers being so closely linked to the produced artifacts. We already have the commit data for every release, but we don&rsquo;t publicise it internally at the moment, this is something I&rsquo;m going to mull over&hellip;  I do think that as our usage of automation testing improves, so our testers are freed from having to spend the majority of their time writing automation suites, and can focus more on exploratory testing, like the Nissan QAs.</p>

<p><img class="center" src="http://engineering.bedegaming.com/images/bt-commiters.png" title="Commit statistics for a Bede component" alt="Commit statistics for a Bede component"></p>

<h3>Kaizen</h3>

<p>Kaizen is a fancy word for continuous improvement. Key to this is accepting that process nirvana is an unachievable state, but that there is always something that can be done to move you closer to perfection. Suggestions for process improvement are grass roots as well as management driven. I think we can say the same for Bede - after working hard on Agile process, we are starting to find that team members initiate as much process change as managers. We&rsquo;ve worked hard to create a <a href="https://hbr.org/2013/01/to-increase-innovation-take-th/">smart-fail</a> culture, where employees feel confident to try things out.  Nissan don&rsquo;t offer incentives for improvements. An employee could suggest an improvement that saves the plant 1% of its running costs, but the staff member won&rsquo;t see a penny of that. At first I thought this was backward - why not incentivise staff to suggest improvements; but perhaps Nissan have nailed the culture so well that staff see it as their duty to continuously improve process.</p>

<h3>Leverage your bottlenecks</h3>

<p>At one particular work centre, the chassis lifts up and passes overhead so that fitters can tighten up some bolts on the underside of the vehicle. The air tool used for this job is obviously very heavy, it used to be a difficult job and production managers complained of fatigue and minor injury rates at the workstation. Staff suggested building a semi-robotic arm, essentially taking the weight of the tool, but allowing the operator to position it as necessary. The plant&rsquo;s internal engineering team obliged, and the problem is now solved. This is a great example of leveraging the bottleneck at this workstation. For more on bottlenecks and constraints theory, see the reading recommendations at the end of this post. The obvious comparison in the world of bits is automation. Reducing repetition, with its accompanying opportunities for mistakes and time wastage.</p>

<h3>Staff Liquidity</h3>

<p>Nissan has a dedicated training academy on site, in partnership with a local college.  The main goal of training is to get new employees up to the point that they can effectively perform at least 3 different workstation tasks to an acceptable level - staff are rotated frequently, even within shifts.  This kind of staff liquidity ensures that when there&rsquo;s a bout of flu going around, the production line doesn&rsquo;t grind to a halt - there are others trained to pick up the slack in any workstation. If things get desperate, line supervisors and managers are expected to get down to the shop floor and keep things running.</p>

<p>Liquidity is something that Bede software teams are still working to improve.  We&rsquo;ve removed as many dependencies on specific individuals as possible, but there isn&rsquo;t yet perfect liquidity. Paul has blogged previously on this subject, in <a href="http://engineering.bedegaming.com/blog/2014/10/16/who-is-your-brent/">Who is your brent</a>. I think the KPI for staff liquidity is when we proactively move &lsquo;key&rsquo; staff between teams. This has always been a long term aim - keeping engineers fresh by moving them around and exposing them to new problems, helping good ideas and practices to pollinate between teams, and further increasing liquidity.</p>

<p>Enjoyed this article? You should probably read <a href="http://www.amazon.co.uk/The-Phoenix-Project-Helping-Business-ebook/dp/B00AZRBLHO">The Phoenix Project</a>, or even better, go back to the source with <a href="http://www.amazon.co.uk/Goal-Process-Ongoing-Improvement-ebook/dp/B002LHRM2O/ref=sr_1_1?s=digital-text&amp;ie=UTF8&amp;qid=1415278766&amp;sr=1-1&amp;keywords=the+goal">The Goal</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Modelling an nginx Application Proxy using Puppet and Hiera]]></title>
    <link href="http://engineering.bedegaming.com/blog/2014/11/05/modelling-an-nginx-application-proxy-using-puppet-and-hiera/"/>
    <updated>2014-11-05T15:53:08+00:00</updated>
    <id>http://engineering.bedegaming.com/blog/2014/11/05/modelling-an-nginx-application-proxy-using-puppet-and-hiera</id>
    <content type="html"><![CDATA[<h1>Goal</h1>

<p>To model nginx configurations in Hiera, extracting those configurations from the Puppet DSL, and create a Puppet Profile to combine that with the nginx module.</p>

<!-- more -->


<h1>Links</h1>

<h2>Puppet Docs</h2>

<ul>
<li><a href="https://docs.puppetlabs.com/learning/ral.html">Puppet Resource Abstraction Layer</a></li>
<li><a href="https://docs.puppetlabs.com/references/latest/function.html#createresources">Puppet create_resources</a></li>
<li><a href="https://docs.puppetlabs.com/guides/scope_and_puppet.html">Scoping</a></li>
<li><a href="https://docs.puppetlabs.com/puppet/latest/reference/lang_namespaces.html">Namespacing</a></li>
</ul>


<h2>Puppet Roles/Profiles</h2>

<ul>
<li><a href="http://www.slideshare.net/PuppetLabs/roles-talk">Craig Dunn, Designing Puppet Talk</a></li>
<li><a href="https://ask.puppetlabs.com/question/1655/an-end-to-end-roleprofile-example-using-hiera/">End to End Roles and Profiles Example</a></li>
<li><a href="http://garylarizza.com/blog/2014/02/17/puppet-workflow-part-1/">Puppet Workflow Part 1</a></li>
<li><a href="http://garylarizza.com/blog/2014/02/17/puppet-workflow-part-2/">Puppet Workflow Part 2</a></li>
</ul>


<h2>Hiera</h2>

<ul>
<li><a href="https://docs.puppetlabs.com/hiera/1/">Puppet Labs Hiera Docs</a></li>
<li><a href="https://docs.puppetlabs.com/hiera/1/variables.html#passing-variables-to-hiera">Passing Variables to Hiera</a></li>
</ul>


<h2>nginx Module</h2>

<ul>
<li><a href="https://github.com/jfryman/puppet-nginx">jfryman nginx Puppet Module</a></li>
</ul>


<h2>nginx</h2>

<ul>
<li><a href="http://wiki.nginx.org/Main">nginx Project Page</a></li>
</ul>


<h1>Requirements</h1>

<p>Within nginx we need to define a set of nginx &ldquo;server&rdquo; contexts with the
same set of &ldquo;location&rdquo; contexts in each &ldquo;server&rdquo;.</p>

<p>Think of this as &ldquo;<a href="http://SiteA.com">http://SiteA.com</a>&rdquo; and &ldquo;<a href="http://SiteB.com">http://SiteB.com</a>&rdquo;, that both
have the same set of &ldquo;locations&rdquo;, which define the nginx upstreams
(backends), that combined provide a single site that is created from
disparate SOA applications.</p>

<p>This is essentially a model to build a nginx based proxy layer sitting
in front of a multi-tenant SOA application stack.</p>

<h2>Approach</h2>

<p><em>Example 1: Single Server, Two Locations modelled in Hiera (YAML)</em></p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>proxy::sites::vhosts:
</span><span class='line'>  SiteA:
</span><span class='line'>    listen_port : 8080
</span><span class='line'>    rewrite_to_https : false
</span><span class='line'>    use_default_location : false
</span><span class='line'>
</span><span class='line'>proxy::sites::locations:
</span><span class='line'>  root:
</span><span class='line'>    vhost : SiteA
</span><span class='line'>    location : '/'
</span><span class='line'>    ensure : 'present'
</span><span class='line'>    proxy : 'http://serviceA'
</span><span class='line'>  server_status: 
</span><span class='line'>    vhost : SiteA
</span><span class='line'>    location : '/server-status'
</span><span class='line'>    ensure : 'present'
</span><span class='line'>    stub_status : true</span></code></pre></td></tr></table></div></figure>


<p>In this example we have a single &ldquo;server&rdquo;, called SiteA. SiteA also has 2 locations defined, &ldquo;root&rdquo;, and &ldquo;server-status&rdquo;.</p>

<p>The relationship between the server and location is defined by the parameter &ldquo;vhost&rdquo; in the location stanza; by being set to &ldquo;SiteA&rdquo;, the location stanza is created within the SiteA server stanza, when all this is realized into an actual nginx configuration file.</p>

<p>There are possibly other Hiera/YAML structures that would allow us to
model this relationship more clearly, however we&rsquo;re using this specific
structure because we want to take advantage of Puppets
<code>create_resources</code> function in conjunction with the nginx module:</p>

<ul>
<li><a href="https://docs.puppetlabs.com/references/latest/function.html#createresources">https://docs.puppetlabs.com/references/latest/function.html#createresources</a></li>
</ul>


<p>Essentially, with the data structured in the correct manner we can pass
it to <code>create_resources</code> as a Puppet hash and it will create the
specified resource. In this case the specific resources are the location
and vhost resources defined in the nginx module. By defining our config
data in Hiera in the right structure, we can use <code>create_resources</code> and
make our life a bit simpler.</p>

<p>This presents a challenge when you want to create more than one server
(multiple vhosts).</p>

<p><em>Example 2: Two vhosts, Two locations</em></p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>proxy::sites::vhosts:
</span><span class='line'>  SiteA:
</span><span class='line'>    listen_port : 8080
</span><span class='line'>    rewrite_to_https : false
</span><span class='line'>    use_default_location : false
</span><span class='line'>  SiteB:
</span><span class='line'>    listen_port : 8080
</span><span class='line'>    rewrite_to_https : false
</span><span class='line'>    use_default_location : false
</span><span class='line'>
</span><span class='line'>proxy::sites::locations:
</span><span class='line'>  root:
</span><span class='line'>    vhost : SiteA
</span><span class='line'>    location : '/'
</span><span class='line'>    ensure : 'present'
</span><span class='line'>    proxy : 'http://serviceA
</span><span class='line'>  server_status:
</span><span class='line'>    vhost : SiteA
</span><span class='line'>    location : '/server-status'
</span><span class='line'>    ensure : 'present'
</span><span class='line'>    stub_status : true</span></code></pre></td></tr></table></div></figure>


<p>You now have 2 servers/vhosts. However the location stanzas are only
related to the first server/vhost (SiteA), as specified by the locations
vhost paramater.</p>

<p>In order to create a &ldquo;root&rdquo; and &ldquo;server_status&rdquo; location for SiteB,
following the same model as above, you would end up with:</p>

<p><em>Example 3: Two vhosts, Four locations (2 per vhost)</em></p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>proxy::sites::vhosts:
</span><span class='line'>  SiteA:
</span><span class='line'>    listen_port : 8080
</span><span class='line'>    rewrite_to_https : false
</span><span class='line'>    use_default_location : false
</span><span class='line'>  SiteB:
</span><span class='line'>    listen_port : 8080
</span><span class='line'>    rewrite_to_https : false
</span><span class='line'>    use_default_location : false
</span><span class='line'>
</span><span class='line'>proxy::sites::locations:
</span><span class='line'>  SiteA_root:
</span><span class='line'>    vhost : SiteA
</span><span class='line'>    location : '/'
</span><span class='line'>    ensure : 'present'
</span><span class='line'>    proxy : 'http://serviceA
</span><span class='line'>  SiteA_server_status:
</span><span class='line'>    vhost : SiteA
</span><span class='line'>    location : '/server-status'
</span><span class='line'>    ensure : 'present'
</span><span class='line'>    stub_status : true
</span><span class='line'>  SiteB_root:
</span><span class='line'>    vhost : SiteB
</span><span class='line'>    location : '/'
</span><span class='line'>    ensure : 'present'
</span><span class='line'>    proxy : 'http://serviceA
</span><span class='line'>  SiteB_server_status:
</span><span class='line'>    vhost : SiteB
</span><span class='line'>    location : '/server-status'
</span><span class='line'>    ensure : 'present'
</span><span class='line'>    stub_status : true</span></code></pre></td></tr></table></div></figure>


<p>This is obviously suboptimal as you&rsquo;re repeating configuration for both
locations now. For each vhost SiteA and SiteB, you need to define 2
locations.</p>

<p>You&rsquo;ll also notice that the name of the locations have now changed to
&ldquo;SiteA_root&rdquo;, &ldquo;SiteA_server_status&rdquo; and &ldquo;SiteB_root&rdquo;,
&ldquo;SiteB_server_status&rdquo;. This is due to Puppet not allowing duplicate
resource declarations, which these locations would be if they were both
named &ldquo;root&rdquo; and &ldquo;server_status&rdquo;. So we create unique resources, by
making the resource names unique.</p>

<p>You can see where this is leading. For every vhost that we want to add,
that has the same set of locations, we&rsquo;ll end up duplicating the
location data, and just changing the location name and the vhost the
location is associated with. This is probably bad, at least it feels
very bad to me.</p>

<p>The natural response to this is &ldquo;Simples! I&rsquo;ll just iterate over the
list of vhosts and create the set of locations for each server!&rdquo;.</p>

<p>Nope. Not really.</p>

<p>Puppet DSL doesn&rsquo;t really do iteration. Not naturally anyhow.</p>

<p>My favorite comment on this:</p>

<ul>
<li><a href="http://stackoverflow.com/questions/12958114/how-to-iterate-over-an-array-in-puppet/13008766#13008766">http://stackoverflow.com/questions/12958114/how-to-iterate-over-an-array-in-puppet/13008766#13008766</a></li>
</ul>


<p>Quote: &ldquo;The Puppet developers have irrational prejudices against
iteration based on a misunderstanding about how declarative languages
work.&rdquo;</p>

<p>(Disclaimer: I&rsquo;m not a dev, I won&rsquo;t attempt to evaluate the truth of
that statement, but I still think its amusing)</p>

<p>So we have 2 problems:</p>

<ol>
<li>Iteration in Puppet is notâ¦ normal, allowed, right, easy?</li>
<li>The &ldquo;names&rdquo; of the locations need to be unique, which means they
can&rsquo;t simply be text labels in YAML. There must be some
interpolation somewhere.</li>
</ol>


<p>We&rsquo;ll deal with the second problem first, as it&rsquo;s a slightly easier
problem to solve, at least in my experience.</p>

<h2>Hiera Interpolation</h2>

<p>Hiera/Puppet allows variables to be passed into Hiera:</p>

<ul>
<li><a href="https://docs.puppetlabs.com/hiera/1/variables.html#passing-variables-to-hiera">https://docs.puppetlabs.com/hiera/1/variables.html#passing-variables-to-hiera</a></li>
</ul>


<p>Quote: &ldquo;When used with Puppet, Hiera automatically receives all of
Puppet&rsquo;s current variables. This includes facts and built-in variables,
as well as local variables from the current scope&rdquo;.</p>

<p>This means we can pass Hiera some variable defined within the Puppet
Manifest, and hopefully therereby creating dynamically named nginx
location resources within Puppet. Probably the most important bit of
that quote is that Hiera has access to &ldquo;local variables from the current
scope&rdquo;. That&rsquo;ll be touched upon further on in this article.</p>

<p>So, that would look something like Example 4.</p>

<p><em>Example 4: Two vhosts, 2 dynamically named locations</em></p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>proxy::sites::vhosts:
</span><span class='line'>  SiteA:
</span><span class='line'>    listen_port : 8080
</span><span class='line'>    rewrite_to_https : false
</span><span class='line'>    use_default_location : false
</span><span class='line'>  SiteB:
</span><span class='line'>    listen_port : 8080
</span><span class='line'>    rewrite_to_https : false
</span><span class='line'>    use_default_location : false
</span><span class='line'>
</span><span class='line'>proxy::sites::locations:
</span><span class='line'>  "%{vhost}_root":
</span><span class='line'>    vhost : "%{vhost}"
</span><span class='line'>    location : '/'
</span><span class='line'>    ensure : 'present'
</span><span class='line'>    proxy : 'http://serviceA
</span><span class='line'>  "%{vhost}_server_status":
</span><span class='line'>    vhost : "%{vhost}"
</span><span class='line'>    location : '/server-status'
</span><span class='line'>    ensure : 'present'
</span><span class='line'>    stub_status : true</span></code></pre></td></tr></table></div></figure>


<p>So, without getting into the intricate details, this suggests that the
nginx location resources will be named <code>&lt;vhost&gt;_&lt;location&gt;</code>. The goal
would be to end up with 4 locations, 2 assigned to each vhost.</p>

<p><em>Example 5: Locations per Vhost</em></p>

<table style="width:100%">
  <tr>
    <th>Vhost</td>
    <th>Location Name</td> 
  </tr>
  <tr>
    <td>SiteA</td>
    <td>SiteA_root</td> 
  </tr>
  <tr>
    <td></td>
    <td>SiteA_server_status</td> 
  </tr>
  <tr>
    <td>SiteB</td>
    <td>SiteB_root</td> 
  </tr>
  <tr>
    <td></td>
    <td>SiteB_server_status </td> 
  </tr>
</table>


<p>The next problem to solve is how to iterate over the list of vhosts.</p>

<h2>Puppet Iteration</h2>

<p>As mentioned, Puppet doesn&rsquo;t really do iteration natively (ignoring the
future parser for now). So how do we accomplish this using native Puppet
DSL?</p>

<p>The first thing to realize is that iteration does in fact happen (or
something similar enough that the difference doesnt matter to most
people). A very good and clear blog article about this can be found
here:</p>

<ul>
<li><a href="https://tobrunet.ch/2013/01/iterate-over-datastructures-in-puppet-manifests/">https://tobrunet.ch/2013/01/iterate-over-datastructures-in-puppet-manifests/</a></li>
</ul>


<p>The basic point being made is that native Puppet functions will iterate
over a Puppet array, executing for each array member.</p>

<p>The first example on that blog post is as follows.</p>

<p><em>Example 6: Iteration in Puppet DSL</em></p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>define arrayDebug {
</span><span class='line'> notify { [Item ${name}]() }
</span><span class='line'>}
</span><span class='line'>
</span><span class='line'>class array {
</span><span class='line'> $array = [ 'item1', 'item2', 'item3' ]
</span><span class='line'> arrayDebug { $array: }
</span><span class='line'>}</span></code></pre></td></tr></table></div></figure>


<p>Essentially the <code>arrayDebug</code> resource (define) will iterate over the
array members of the array <code>$array</code>.</p>

<h2>Creating a Puppet Profile</h2>

<p>So the next step is to write a Puppet &ldquo;Profile&rdquo; for nginx that
encapsulates the functionality we want, using Hiera as the data source,
and the nginx module as the underlying component.</p>

<p>Lets start by creating the basic Hiera config needed for a very simple
nginx install.</p>

<p><em>Example 7: Hiera for nginx</em></p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>nginx::default::mail : false
</span><span class='line'>nginx::default::worker_processes : %{processorcount}
</span><span class='line'>nginx::default::server_tokens : 'off'
</span><span class='line'>nginx::default::nginx_error_log : '/var/log/nginx/error.log debug'
</span><span class='line'>nginx::default::http_access_log : '/var/log/nginx/access.log'
</span><span class='line'>nginx::default::proxy_cache_path : '/var/cache/nginx'
</span><span class='line'>nginx::default::proxy_cache_levels : '2'
</span><span class='line'>nginx::default::proxy_cache_keys_zone : 'cache:10m'
</span><span class='line'>nginx::default::proxy_cache_max_size : '2048m'</span></code></pre></td></tr></table></div></figure>


<p>There&rsquo;s nothing exceptional here, this is all nginx boilerplate to set
some global defaults for nginx. The interesting bit of this is when we
start creating the nginx Profile.</p>

<p><em>Example 8: Base nginx Profile in Puppet DSL</em></p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>class profile::linux::nginx {
</span><span class='line'>
</span><span class='line'>  $mail                           = hiera('nginx::default::mail')
</span><span class='line'>  $worker_processes               = hiera('nginx::default::worker_processes')
</span><span class='line'>  $server_tokens              = hiera('nginx::default::server_tokens')
</span><span class='line'>  $nginx_error_log                = hiera('nginx::default::nginx_error_log')
</span><span class='line'>  $http_access_log                = hiera('nginx::default::http_access_log')
</span><span class='line'>  $proxy_cache_path               = hiera('nginx::default::proxy_cache_path')
</span><span class='line'>  $proxy_cache_levels         = hiera('nginx::default::proxy_cache_levels')
</span><span class='line'>  $proxy_cache_keys_zone      = hiera('nginx::default::proxy_cache_keys_zone')
</span><span class='line'>  $proxy_cache_max_size           = hiera('nginx::default::proxy_cache_max_size')
</span><span class='line'>  $names_hash_bucket_size     = hiera('nginx::default::names_hash_bucket_size')
</span><span class='line'>
</span><span class='line'>  #################################################
</span><span class='line'>  # Create the base nginx config by passing the nginx module the minimum config that we use across all our systems
</span><span class='line'>  #################################################
</span><span class='line'>
</span><span class='line'>  class { '::nginx':
</span><span class='line'>    mail                      =&gt; $mail,
</span><span class='line'>    worker_processes          =&gt; $worker_processes,
</span><span class='line'>    server_tokens                 =&gt; $server_tokens,
</span><span class='line'>    nginx_error_log           =&gt; $nginx_error_log,
</span><span class='line'>    http_access_log           =&gt; $http_access_log,
</span><span class='line'>    proxy_cache_path          =&gt; $proxy_cache_path,
</span><span class='line'>    proxy_cache_levels            =&gt; $proxy_cache_levels,
</span><span class='line'>    proxy_cache_keys_zone         =&gt; $proxy_cache_keys_zone,
</span><span class='line'>    proxy_cache_max_size      =&gt; $proxy_cache_max_size,
</span><span class='line'>    names_hash_bucket_size        =&gt; $names_hash_bucket_size,
</span><span class='line'>  }
</span><span class='line'>}</span></code></pre></td></tr></table></div></figure>


<p>So this is all pretty simple again. This is a Puppet class called
<code>profile::linux::nginx</code>, which sets some default variables, and passes
them to another class called <code>::nginx</code>.</p>

<p>This class is a &ldquo;Profile&rdquo; simply by dint of it being created within the
Profile module / namespace. It&rsquo;s technically no different than any other
Puppet module, it&rsquo;s simply a widely accepted convention that Puppet
Roles and Profiles are modules.</p>

<p>The <code>::nginx</code> class actually refers to the nginx module, denoted by the
leading <code>::</code>, basically meaning &ldquo;at top scope, named nginx&rdquo;.</p>

<p>If you&rsquo;re wondering about the <code>::</code> colon syntax, start by reading about
Puppet scope and namespacing:</p>

<ul>
<li><a href="https://docs.puppetlabs.com/guides/scope_and_puppet.html">https://docs.puppetlabs.com/guides/scope_and_puppet.html</a></li>
<li><a href="https://docs.puppetlabs.com/puppet/latest/reference/lang_namespaces.html">https://docs.puppetlabs.com/puppet/latest/reference/lang_namespaces.html</a></li>
</ul>


<p>So this nginx Profile achieves the very first of our goals; that is to
install nginx and set some very basic global nginx parameters.</p>

<p>The next step would be create the nginx &ldquo;servers&rdquo; (called vhosts here).
In order to achieve this step we need to retrieve the vhost
configuration data from Hiera. We&rsquo;ll then use that data to create the
vhosts.</p>

<p><em>Example 9: nginx Profile with vhosts being created</em></p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>class profile::linux::nginx {
</span><span class='line'>
</span><span class='line'>  $mail                           = hiera('nginx::default::mail')
</span><span class='line'>  $worker_processes               = hiera('nginx::default::worker_processes')
</span><span class='line'>  $server_tokens              = hiera('nginx::default::server_tokens')
</span><span class='line'>  $nginx_error_log                = hiera('nginx::default::nginx_error_log')
</span><span class='line'>  $http_access_log                = hiera('nginx::default::http_access_log')
</span><span class='line'>  $proxy_cache_path               = hiera('nginx::default::proxy_cache_path')
</span><span class='line'>  $proxy_cache_levels         = hiera('nginx::default::proxy_cache_levels')
</span><span class='line'>  $proxy_cache_keys_zone      = hiera('nginx::default::proxy_cache_keys_zone')
</span><span class='line'>  $proxy_cache_max_size           = hiera('nginx::default::proxy_cache_max_size')
</span><span class='line'>  $names_hash_bucket_size     = hiera('nginx::default::names_hash_bucket_size')
</span><span class='line'>
</span><span class='line'>  #################################################
</span><span class='line'>  # Get the hash of vhosts from Hiera. Extract the hash keys into a list (array).
</span><span class='line'>  #################################################
</span><span class='line'>
</span><span class='line'>  $vhosts                     = hiera('proxy::sites::vhosts')
</span><span class='line'>
</span><span class='line'>  #################################################
</span><span class='line'>  # Create the base nginx config by passing the nginx module the minimum config that we use across all our systems
</span><span class='line'>  #################################################
</span><span class='line'>
</span><span class='line'>  class { '::nginx':
</span><span class='line'>    mail                      =&gt; $mail,
</span><span class='line'>    worker_processes          =&gt; $worker_processes,
</span><span class='line'>    server_tokens                 =&gt; $server_tokens,
</span><span class='line'>    nginx_error_log           =&gt; $nginx_error_log,
</span><span class='line'>    http_access_log           =&gt; $http_access_log,
</span><span class='line'>    proxy_cache_path          =&gt; $proxy_cache_path,
</span><span class='line'>    proxy_cache_levels            =&gt; $proxy_cache_levels,
</span><span class='line'>    proxy_cache_keys_zone         =&gt; $proxy_cache_keys_zone,
</span><span class='line'>    proxy_cache_max_size      =&gt; $proxy_cache_max_size,
</span><span class='line'>    names_hash_bucket_size        =&gt; $names_hash_bucket_size,
</span><span class='line'>  }
</span><span class='line'>
</span><span class='line'>  ################################################
</span><span class='line'>  # Create the ngingx vhosts (server blocks in nginx config terms). Pass create_resources the hash retrieved from Hiera,
</span><span class='line'>  # into the nginx::resource::vhost resource defined by the nginx module
</span><span class='line'>  ################################################
</span><span class='line'>
</span><span class='line'>  create_resources('::nginx::resource::vhost', $vhosts)
</span><span class='line'>
</span><span class='line'>}</span></code></pre></td></tr></table></div></figure>


<p>First we add some functionality to retrieve the vhost config from Hiera
using a Hiera lookup function in Puppet:</p>

<pre><code>$vhosts = hiera('proxy::walletv2::vhosts')
</code></pre>

<p>We then pass the resultant hash to a Puppet function called
<code>create_resrouces</code>:</p>

<pre><code>create_resources('::nginx::resource::vhost', $vhosts)
</code></pre>

<p><code>create_resources</code> is a very useful Puppet function. Given the right set
of information, in the right structure, it will auto-magically create
the specified resource. In this case the resource we&rsquo;re talking about is
the <code>::nginx::resource::vhost</code> resource. This resource is defined in the
nginx module, as denoted by the top scope <code>::nginx</code>. The hash <code>$vhosts</code>
contains the data retrieved from Hiera, specifically from the key
<code>proxy::sites::vhosts</code> found in Example 2 to Example 4.</p>

<p>This will create the nginx vhost (server) configurations in the actual
nginx config files, using the key/values as parameters.</p>

<p>Further reading:</p>

<ul>
<li><a href="https://docs.puppetlabs.com/references/latest/function.html#createresources">https://docs.puppetlabs.com/references/latest/function.html#createresources</a></li>
<li><a href="https://docs.puppetlabs.com/learning/ral.html">https://docs.puppetlabs.com/learning/ral.html</a></li>
</ul>


<p>The final step is to combine our interpolated Hiera data and Puppet
iteration learnings into the Profile so that each vhost that gets
created, also gets the same set of locations.</p>

<p><em>Example 10: nginx Profile with vhosts and locations being created</em></p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
<span class='line-number'>46</span>
<span class='line-number'>47</span>
<span class='line-number'>48</span>
<span class='line-number'>49</span>
<span class='line-number'>50</span>
<span class='line-number'>51</span>
<span class='line-number'>52</span>
<span class='line-number'>53</span>
<span class='line-number'>54</span>
<span class='line-number'>55</span>
<span class='line-number'>56</span>
<span class='line-number'>57</span>
<span class='line-number'>58</span>
<span class='line-number'>59</span>
<span class='line-number'>60</span>
<span class='line-number'>61</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>class profile::linux::nginx {
</span><span class='line'>
</span><span class='line'>  $mail                           = hiera('nginx::default::mail')
</span><span class='line'>  $worker_processes               = hiera('nginx::default::worker_processes')
</span><span class='line'>  $server_tokens              = hiera('nginx::default::server_tokens')
</span><span class='line'>  $nginx_error_log                = hiera('nginx::default::nginx_error_log')
</span><span class='line'>  $http_access_log                = hiera('nginx::default::http_access_log')
</span><span class='line'>  $proxy_cache_path               = hiera('nginx::default::proxy_cache_path')
</span><span class='line'>  $proxy_cache_levels         = hiera('nginx::default::proxy_cache_levels')
</span><span class='line'>  $proxy_cache_keys_zone      = hiera('nginx::default::proxy_cache_keys_zone')
</span><span class='line'>  $proxy_cache_max_size           = hiera('nginx::default::proxy_cache_max_size')
</span><span class='line'>  $names_hash_bucket_size     = hiera('nginx::default::names_hash_bucket_size')
</span><span class='line'>
</span><span class='line'>  #################################################
</span><span class='line'>  # Get the hash of vhosts from Hiera. Extract the hash keys into a list (array).
</span><span class='line'>  #################################################
</span><span class='line'>
</span><span class='line'>  $vhosts                     = hiera('proxy::sites::vhosts')
</span><span class='line'>  $vhostslist                 = keys($vhosts)
</span><span class='line'>
</span><span class='line'>  #################################################
</span><span class='line'>  # Create the base nginx config by passing the nginx module the minimum config that we use across all our systems
</span><span class='line'>  #################################################
</span><span class='line'>
</span><span class='line'>  class { '::nginx':
</span><span class='line'>    mail                      =&gt; $mail,
</span><span class='line'>    worker_processes          =&gt; $worker_processes,
</span><span class='line'>    server_tokens                 =&gt; $server_tokens,
</span><span class='line'>    nginx_error_log           =&gt; $nginx_error_log,
</span><span class='line'>    http_access_log           =&gt; $http_access_log,
</span><span class='line'>    proxy_cache_path          =&gt; $proxy_cache_path,
</span><span class='line'>    proxy_cache_levels            =&gt; $proxy_cache_levels,
</span><span class='line'>    proxy_cache_keys_zone         =&gt; $proxy_cache_keys_zone,
</span><span class='line'>    proxy_cache_max_size      =&gt; $proxy_cache_max_size,
</span><span class='line'>    names_hash_bucket_size        =&gt; $names_hash_bucket_size,
</span><span class='line'>  }
</span><span class='line'>
</span><span class='line'>  ################################################
</span><span class='line'>  # Create the ngingx vhosts (server blocks in nginx config terms). Pass create_resources the hash retrieved from Hiera,
</span><span class='line'>  # into the nginx::resource::vhost resource defined by the nginx module
</span><span class='line'>  ################################################
</span><span class='line'>
</span><span class='line'>  create_resources('::nginx::resource::vhost', $vhosts)
</span><span class='line'>
</span><span class='line'>  define profile::linux::nginx::location {
</span><span class='line'>    ### Creating Locations
</span><span class='line'>    $locations = hiera('proxy::sites::locations')
</span><span class='line'>    $vhostslocations = { vhost =&gt; $name }
</span><span class='line'>
</span><span class='line'>    create_resources('::nginx::resource::location', $locations, $vhostslocations)
</span><span class='line'>  }
</span><span class='line'>
</span><span class='line'>  ################################################
</span><span class='line'>  #
</span><span class='line'>  # This calls the above define per member of $vhostslist array
</span><span class='line'>  #
</span><span class='line'>  ################################################
</span><span class='line'>
</span><span class='line'>  profile::linux::nginx::location { $vhostslist: }
</span><span class='line'>
</span><span class='line'>}</span></code></pre></td></tr></table></div></figure>


<p>So what have we done here?</p>

<p>The first thing is that we&rsquo;ve added an array called <code>$vhostslist</code>, whos
array members are made up of the key names of the <code>$vhosts</code> hash:</p>

<pre><code>$vhostslist = keys($vhosts)
</code></pre>

<p>This gives us the array that we want to iterate over, as discussed in
the Puppet iteration section. The array members in this example will be
&ldquo;SiteA&rdquo; and &ldquo;SiteB&rdquo;, i.e. <code>[ "SiteA", "SiteB" ]</code>.</p>

<p>The second thing we&rsquo;ve added is a new define,
<code>profile::linux::nginx::location</code>:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>define profile::linux::nginx::location {
</span><span class='line'>  ### Creating Locations
</span><span class='line'>  $locations = hiera('proxy::sites::locations')
</span><span class='line'>  $vhostslocations = { vhost =&gt; $name }
</span><span class='line'>
</span><span class='line'>  create_resources('::nginx::resource::location', $locations, $vhostslocations)
</span><span class='line'> }</span></code></pre></td></tr></table></div></figure>


<p>This can be thought of as a function in more general programming
languages, that will iterate over the array <code>$vhostslist</code>. Within this
define we are retrieving the list of locations into a has called
<code>$locations</code>, using another Hiera lookup, on the key
<code>proxy::sites::locations</code> (Yes I&rsquo;m aware this will be done for every
iteration, not optimal). We then create a new hash called
<code>$vhostslocations</code> which contains the key <code>vhost</code> and value <code>$name</code>,
i.e. <code>{ vhost =&gt; $name }</code>.</p>

<p>Once we have the <code>$locations</code> hash and the <code>$vhostslocations</code> hash, we
then call <code>create_resources</code>. Just like the previous time we called
<code>create_resources</code>, the specific resource is defined by the nginx
module, and is called <code>::nginx::resource::location</code>. However, in this
case we&rsquo;re giving the <code>create_resources</code> function two items, not one.
The first item is the list of locations we&rsquo;d like to create, and the
second is the <code>$vhostslocations</code> hash.</p>

<p>The second optional item passed to <code>create_resources</code> (
<code>$vhostslocations</code> ) is an anonymous hash of extra parameters to add to
the resource being created.</p>

<p>This define is then &ldquo;called&rdquo; by the line:</p>

<pre><code>profile::linux::nginx::location { $vhostslist: }
</code></pre>

<p>Before we go further, we need to look at the Hiera data again, and
modify it slightly:</p>

<p><em>Example 11: Modified Hiera data</em></p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>proxy::sites::vhosts:
</span><span class='line'>  SiteA:
</span><span class='line'>    listen_port : 8080
</span><span class='line'>    rewrite_to_https : false
</span><span class='line'>    use_default_location : false
</span><span class='line'>  SiteB:
</span><span class='line'>    listen_port : 8080
</span><span class='line'>    rewrite_to_https : false
</span><span class='line'>    use_default_location : false
</span><span class='line'>
</span><span class='line'>proxy::sites::locations:
</span><span class='line'>  "%{name}_root"
</span><span class='line'>    location : '/'
</span><span class='line'>    ensure : 'present'
</span><span class='line'>    proxy : 'http://serviceA'
</span><span class='line'>  "%{name}_server_status"
</span><span class='line'>    location : '/server-status'
</span><span class='line'>    ensure : 'present'
</span><span class='line'>    stub_status : true</span></code></pre></td></tr></table></div></figure>


<p>The change here is the variable we want interpolated has been changed to
<code>%{name}</code>, and the <code>vhost</code> parameter has been removed.</p>

<p>You&rsquo;ll notice in Example 10 the newly added define suddenly makes use of
a variable called <code>$name</code>. We&rsquo;re also now referencing it in our modified
Hiera config in Example 11.</p>

<p>So what is <code>$name</code>? Well, this goes back to Puppet resources again. The
define <code>profile::linux::nginx::location</code> <strong>is</strong> a Puppet resource, and
as such must be &ldquo;named&rdquo; (and again, named uniquely). When we call the
define:</p>

<pre><code>profile::linux::nginx::location { $vhostslist: }
</code></pre>

<p>We&rsquo;re passing it the array that it iterates over, but under the hood in
a bit of Puppet magic, the &ldquo;name&rdquo; of the resource becomes the value of
the array member. So there will be two resources of type
<code>profile::linux::nginx::location</code>, one named &ldquo;SiteA&rdquo; and the other named
&ldquo;SiteB&rdquo;. Within the scope of each of these resources, Puppet creates and
makes available a variable called <code>$name</code>, which of course is set to the
&ldquo;name&rdquo; of the resource, or in our case &ldquo;SiteA&rdquo; and SiteB&#8221;.</p>

<p>Since we are performing a Hiera lookup within the resource (define)
<code>profile::linux::nginx::location</code>, that Hiera lookup now has access to
all the Puppet variables within that scope (see previous info about
Hiera being passed Puppet variables). Therefore the <code>%{name}</code> Hiera
variable is set to the <code>$name</code> Puppet variable. Magic.</p>

<p>The final piece of the puzzle is the <code>$vhostslocations</code> hash, and the
actual use of the <code>$name</code> variable. According to the <code>create_resources</code>
documentation:</p>

<p>&ldquo;The values given on the third argument are added to the parameters of
each resource present in the set given on the second argument.&rdquo;</p>

<p>So therefore the hash <code>$vhostslocations { vhost =&gt; "$name" }</code> basically
gives the nginx module an extra parameter that is applied to each
location created of &ldquo;vhost => SiteA&rdquo; or &ldquo;vhost => SiteB&rdquo;. This
establishes the relationship between the locations and their parent
vhosts.</p>

<p>Put it all together and we now have a start towards cleanly modelling
nginx configurations in Hiera, without repeating data, and using the
Roles and Profile pattern. This allows us to completely extract site
configuration data from the Puppet DSL, by providing an abstraction
layer to the nginx module (the nginx Profile). I didn&rsquo;t actually touch
upon a Puppet Role here, but once you have your Profile(s) created, the
creation of Roles is generally much simpler, as they should be nothing
more than a collection of Profiles. The links provided at the beginning
of this post on Roles/Profiles should make the rest clear.</p>

<p>So that&rsquo;s basically an end-to-end example (although not necessarily 100%
working) of using Hiera to model nginx, and combining that with an
abstraction layer (the Profile) above the nginx module.</p>

<h2>Possible re-factors</h2>

<ol>
<li>Duplicate data in the vhosts configurations could be reduced using
the same iteration trick used for the location configs.</li>
<li>Removing the Hiera lookup from the <code>profile::linux::nginx::location</code>
resource would prevent repeating the lookup.</li>
<li>Remove the use of the <code>$vhostslocations</code> hash. Use Hiera
interpolation to specify the vhost parameter in the location
resource.</li>
<li>Many others I haven&rsquo;t thought of :)</li>
</ol>


<p>If anyone has any improvements, suggestions, comments or criticisms let
me know at mahhy at undertow dot ca.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[How the current mobile landscape affects developers]]></title>
    <link href="http://engineering.bedegaming.com/blog/2014/10/20/developers-and-the-changing-mobile-landscape/"/>
    <updated>2014-10-20T15:55:00+00:00</updated>
    <id>http://engineering.bedegaming.com/blog/2014/10/20/developers-and-the-changing-mobile-landscape</id>
    <content type="html"><![CDATA[<p>A colleague pointed me towards an interesting <a href="http://www.slideshare.net/robnyman/mobile-trends-web-native">presentation</a> that illustrates some dramatic shifts in the mobile market. I think it&rsquo;s important that mobile app developers take a close look at how this may impact apps they are working on. Here we discuss issues and possible solutions to the problems that may arise.</p>

<!-- more -->


<h2>The mobile OS battle</h2>

<p>Whether this can be classed as a battle anymore is up for debate but currently Android leads the way and now owns approximately 85% of the market, compare that to 2012 when it was hitting 69% and in 2011 it was only 36%! Looking across at iOS which has dropped from 18% to 11% in the same time period it is certainly looking like the two big players are still the main targets for users, Blackberry has virtually disappeared and Windows Phone seems more appealing to developers than consumers.</p>

<p>Another interesting point is the disappearance of the &ldquo;Other&rdquo; OS&rsquo;s. In 2011 this figure occupied 30% of the market, it now comprises a tiny 0.7%. My opinion here is that this is mainly to do with some of the big mobile handset manufactors moving away from Symbian as their primary platform. Samsung and Sony Ericsson have of course moved to Android whereas Nokia have adopted the Windows Phone OS. So what does this mean for developers?</p>

<p><img class="center" src="http://engineering.bedegaming.com/images/smartphone-os-market-share.png" title="Smartphone OS Market Share" alt="Smartphone OS Market Share"></p>

<p><em>Source: <a href="http://www.idc.com/prodserv/smartphone-os-market-share.jsp">idc.com</a></em></p>

<h3>Android fragmentation</h3>

<p>Firstly, the fragmentation of the Android market means there are many devices to support whereas on iOS there are a known set of devices to target. This leads to problems with differing device performance levels, screen resolutions and OS versions. For mobile web apps or sites you can add the usual cross browsers incompatibilities to that list.</p>

<h3>High end devices</h3>

<p>Despite Android&rsquo;s 85% market share dwarfing iOS&rsquo;s 11%, you may be surprised to hear that iOS still holds the greater market share when it comes to the high end devices. This is a key consideration to take into account when you analyse the target audience for your app or wesbite.</p>

<h3>App distribution</h3>

<p>Each OS comes with its own app distribution channel, on iOS we have the App Store and Android the Play Store (we should also try not to forget about the Windows Store). The different stores have their own restrictions on the types of app they host, the Play Store for example does not allow gambling apps and also a varying review process. The native language used to develop apps for each OS also varies:</p>

<ul>
<li>Android - Java</li>
<li>iOS - Objective-C / Swift</li>
<li>Windows - C++ / .NET</li>
</ul>


<p>This sets an obvious challenge to developers looking to publish on each store, is it really worth writing an app 3 times?</p>

<h2>So what can we do about it?</h2>

<p>Ok, I&rsquo;ve listed some of the issues that can arise when thinking about developing your latest app or website now how do we solve these isssues? Lets take a look at dealing with the many different devices on the market today. For me, the key here is to know your target audience and plenty of research. Its also useful to consider what your app or site is going to do, ask yourself these questions:</p>

<ol>
<li>What does my app do?</li>
<li>Will it need good hardware?</li>
<li>Am I willing compromise app experience?</li>
</ol>


<p>Three questions that sound obvious but once answered, can really help narrow down that extensive device list - if your app doesnt include rich graphics or intensive animations then its probably safe to widen the range of handsets you are going to target or if it&rsquo;s a game for example then you probably want to stick with the higher end of the market. Likewise if your app is heavily reliant on rich animations and graphics and a reduced experience is not really an option then again this will limit you to the high end devices.</p>

<h3>Development approach</h3>

<p>So we&rsquo;ve limited our device range but we still have a problem in that we need to build the same app 3 times in a different language to reach the maximum number of people. Or do we? No of course not - there are lots of tools available now that allow developers to write once, run anywhere (and no I dont mean Java!). In fact the aforementioned document talks about how almost half of mobile app developers choose to write apps using something other than the native language.</p>

<h4>Unity3D</h4>

<p>Unity is a hugely popular game development tool, it allows its users to create games for a wide variety of platforms. Its performance is a near match for its native equivilents and the quality of games rendering is second to none.</p>

<p>Skills for Unity tend be more difficult to find when compared to native iOS/Android and HTML5, probably because its popularity mainly stems from the games industry, however there is a large community behind it and a new Unity Store where developers can download assets and plugins for their games.</p>

<p>In my opinion, aside from the skill shortage, where Unity falls down is when it comes to app distruption. As with most channels you still have the review process for the various app stores and each new version must go through a similar review.</p>

<h4>Haxe</h4>

<p>Haxe is a relatively new tool that has been brought to my attention recently, it is source to source complier or <em>transpiler</em> for a more appropriate term. This gives developers the ability to write their app once in the Haxe language and &lsquo;transpile&rsquo; into a variety of native languages, current language support includes:</p>

<ul>
<li>iOS</li>
<li>Android</li>
<li>HTML5</li>
<li>Flash</li>
<li>C#</li>
<li>PHP</li>
<li>C++ and more</li>
</ul>


<p>The toolkit has gained backing from some well known companies like Tivo, Prezi and Zynga to name a few and also has a growing open source community which should mean further advances in the native API&rsquo;s. Where this struggles in my opinion is there will always be issues for transpiled languages where some areas of the API dont work cross platform so you maybe forced to restrict functionality in your app to cater for this. That said I imagine the API&rsquo;s available will cater for the majority of apps.</p>

<p>I&rsquo;m not usually a fan of transpilers, I&rsquo;ll stop now before I start a rant about CoffeeScript (one for another post!), but this one certainly looks to have its place in the market and I will be looking into this more in the near future.</p>

<h4>HTML5 and beyond!</h4>

<p>At Bede we are big adovcates of HTML5 and its surrounding technologies. Our games clients make use of the latest HTML5 API&rsquo;s, Javascript frameworks and CSS3 and our CMS uses a variant of responsive design to cater for varying screen resolutions and devices.</p>

<p>All the major mobile platforms support apps built in HTML5. Whether its an app to be published on the app store built with something like <a href="http://cordova.apache.org/">Apache Cordova</a> or one of its distributions, <a href="http://phonegap.com/">PhoneGap</a> is one of the more popular names or a web app saved from the web - Google and Apple are definitely getting behind the HTML5 revolution! An article over at <a href="http://www.sencha.com/blog/apple-shows-love-for-html5-with-ios-8">Sencha</a> details how iOS 8 adds support for many more HTML5 features, couple this with the recent addition of the &lsquo;Nitro&rsquo; Javascript engine to UIWebView and you can see how Apple are embracing HTML5.</p>

<p><img class="center" src="http://engineering.bedegaming.com/images/ios-html5-support.png" title="iOS HTML5 feature support comparison" alt="iOS HTML5 feature support comparison"></p>

<p><em>Source: <a href="http://caniuse.com">caniuse.com</a></em></p>

<p>Google continue to improve the Android experience by making Chrome the default browser in the latest versions of Android, finally ridding HTML5 developers of the native Android browser (or &lsquo;the IE6 of mobile&rsquo; as I like to call it). Performance used to be the main drawback of this approach but the latest developments with full webGL support meaning  hardware accerlation for HTML5 canvas and more powerful devices hitting the market, this is less of a concern these days.</p>

<p>In my opinion HTML5 is succeeding in becoming <em>the</em> write once, run everywhere choice for mobile app development. Maybe only the ultra high performance games have the performance concern now - for the vast majority of developers we can safely rely on HTML5 to deliver what we need in terms of app development. If done correctly the performance difference should be barely noticeable.</p>

<p>An added bonus is that creating a hybrid app with HTML5 means you can auto update you app without needing to go through a review in the app stores for the new content, deploying the latest version to the web will in turn update the app content. This may seem like a small advantage at first but for an app that may require frequent improvements and many iterations it is an invaluable feature.</p>

<p>As described above HTML5 plays a big part in the products delivered by Bede and based on some figures I was shown recently that indicated 40% of traffic on a popular client site came from mobile devices, I believe we are a good case study on the benefits the technology can bring. Aside from the aesthetics of sites and the rich interfaces we can create using the stack, topics like team structure and recruitment strategy are also key bonus points. Across the different teams in Bede a lot of shared code can be utilised - a repository of less mixins is available to developers and our games clients are written using our Javascript framework. Traditionally HTML5 skills have been easier to recruit for than traditional tech skills associated with mobile development, this has allowed Bede to quickly grow a highly talented team.</p>

<p>The main advantage HTML5 gives Bede over its competitors is the ability to rapidly produce rich applications that are highly configurable to the point where it is difficult to identify the software running underneath, compare 2 of our Bingo clients with 2 from a competitor and you will see what I mean!</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Who is your Brent?]]></title>
    <link href="http://engineering.bedegaming.com/blog/2014/10/16/who-is-your-brent/"/>
    <updated>2014-10-16T17:19:00+00:00</updated>
    <id>http://engineering.bedegaming.com/blog/2014/10/16/who-is-your-brent</id>
    <content type="html"><![CDATA[<p>In the book <a href="http://www.amazon.co.uk/Phoenix-Project-DevOps-Helping-Business-ebook/dp/B00AZRBLHO/ref=sr_1_1?s=books&amp;ie=UTF8&amp;qid=1413480244&amp;sr=1-1&amp;keywords=the+phoenix+project">The Phoenix Project</a> one of the primary foils of the &ldquo;hero&rdquo; is a guy named Brent. Brent is critical to successful work. Production incident? Call Brent. Complex database query? Brent&rsquo;s your guy. Tracing down network packet drops? Brent is already on it.  On the face of it, he is what every ops team wants twenty of, but as the book shows it is easy to become so critically dependent on one person that they become a bottleneck for the organisation. Also, Brent has several bad habits. He drops everything he&rsquo;s doing to sort out what ever is being screamed about loudest, regardless of its actual priority. He&rsquo;s also a knowledge silo - because Brent built half the complex systems in the business, he knows <!-- more -->how to solve tricky problems with them all, but all the knowledge is in his head, to the point where most of the rest of the team won&rsquo;t touch those areas. Why would they? Brent can solve the issue in a tenth of the time, and more safely.</p>

<h2>Removing the Bottleneck</h2>

<p>Much of the middle of the book is about how a mentor gets our hero thinking about how to remove that bottleneck. They tried hiring expensive experienced ops people. That failed because they still didn&rsquo;t have the knowledge of Brent, or if they gained it, it was also only in their heads. Part of the solution is to ensure that Brent is literally not allowed to touch the keyboard in production incidents, rather he must explain to a junior staff member how to step through the problems, and document the steps taken, and how to deal with the issue in future. The second part is ensuring visibility of all the work that Brent actually does, not just the stuff that was planned for him. This is one of the other key themes of the book - planned work vs unplanned work.</p>

<h2>Unplanned Work</h2>

<p>Unplanned work is a killer. Production incidents, sneaky off-the-books &ldquo;can you just get something working for me&rdquo; projects from senior management bypassing the project management / prioritisation functions, fixing another persons work because it&rsquo;s been &ldquo;done wrong&rdquo;. Not only does it not appear on your projections of how well you are doing, but it also involves parking what you should be doing, called <em>context switching</em>, or leaving <em>work in progress</em> (WIP). Gaining visibility of all the unplanned work Brent was doing was key to reducing that unplanned work. Sometimes this was even achieved by yelling at very senior management who were demanding that they &ldquo;wanted Brent to look at the issue because he&rsquo;s the best&rdquo;, despite the fact that others were already doing that piece of work.</p>

<p>As Brent&rsquo;s unplanned work went down, it became possible to leverage his actual skillset in high value operations - such as early design review and planning. Without the fire-fighting he is able to take part in processes that reduce the amount of fire-fighting! A virtuous cycle indeed.</p>

<h2>A Person is not a workstation</h2>

<p>In a twist in the later part of the book, the mysterious mentor points out to the hero, via manufacturing analogies, that a Brent is not a work centre or work station. That is, on on the macro level, a person is not a bottleneck, the function that they are carrying out is. In manufacturing you slow down your production of new work items to the speed where they can all be consumed by the next stage without queueing. One of these stations will be the slowest. That is your limiting factor or your bottleneck. (Note - a bottleneck does not specifically mean &ldquo;bad&rdquo;. No matter how optimal your process gets <em>something</em> will be the slowest part).</p>

<h2>Software Development Workstations</h2>

<p>In the software development world, your &ldquo;work stations&rdquo; are things like requirements gathering, planning, architecture and design, implementation, code review, QA testing, deployment to an environment (including production or testing environments). Where is your limiting factor? What stage holds you up the most. One of the great messages in the book is (paraphrased)</p>

<blockquote><p>Any improvements to a process that is not your bottleneck is a fake improvement</p></blockquote>

<p>Basically - because WIP is so bad, anything that does not stop WIP building up at one cost centre is not really reducing the overall turnaround time for work from inception to successful production. You should <em>only</em> focus on improving the bottleneck. When that is no longer the bottleneck, look to the next one.</p>

<h2>Identifying your Bottleneck</h2>

<p>It&rsquo;s actually quite easy to do. Draw a diagram with a box for each process you have from requirements through to in production (generally a straight flow diagram). For each, identify whether they generally have a queue of items from the previous step. Now go from right to left until you find the first item that has a queue. That is your bottle neck.</p>

<p><strong>Example</strong></p>

<blockquote><p>The average queue of stories in the backlog awaiting development work is about 15 items. The average number of stories awaiting QA is 5. The &ldquo;quick&rdquo; answer is to say that clearly the biggest problem is in development - they are coping least well! But think what would happen if you improved that part of the process. QA already has a queue of work - it would only get bigger. There is no point in resolving how much work development can process until QA is no longer the bottleneck.</p></blockquote>

<p>As a real world reminder - here is an recent example from our own boards. You can see that we are building up a bottleneck on QA process. We&rsquo;ve already gone through reviewing the underlying causes. We&rsquo;re tackling this area before re-assessing our next bottleneck.</p>

<p><img class="center" src="http://engineering.bedegaming.com/images/QA-bottleneck-example.png" width="500" height="750" title="image" alt="images"></p>

<h2>Conclusion</h2>

<p>Where is your bottleneck? Who is your Brent? Find them and improve them first, because all other improvements are irrelevant!</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[The Dev-ops 80-20 Rule For Selecting A Database]]></title>
    <link href="http://engineering.bedegaming.com/blog/2014/10/16/the-dev-ops-80-20-rule-for-selecting-a-database/"/>
    <updated>2014-10-16T14:23:57+00:00</updated>
    <id>http://engineering.bedegaming.com/blog/2014/10/16/the-dev-ops-80-20-rule-for-selecting-a-database</id>
    <content type="html"><![CDATA[<p>You&rsquo;re probably already familiar with the 80-20 rule, less catchily known as the <a href="http://en.wikipedia.org/wiki/Pareto_principle">pareto principle</a> - the idea that you spend about 20% of the time it takes to complete a project building out the first 80% of the features, with the remaining 80% of the duration to complete the elusive final 20%.  There are countless applications of this idea - kind of like when youâve just learnt a new word, examples start to crop up everywhere.  The most recent example Iâve come across describes the amount of time spent working with persistence technologies from the point of view of developers and operations.  But first some background.
 <!-- more -->
In the days of working on back office software, if there wasnât a strong opinion already about how to solve a problem, developers were free to pick tools that met their basic checklist - will it work in production? Will the project cover the costs if they exist? And most importantly, HOW SHINY IS IT?</p>

<p>Iâm as guilty as the next developer of having picked tools to work with based primarily on how much I wanted to play with them.  Being an easy tool to code with use generally made my life as a developer easier, but it was also an easy sell to management - if it takes me, the expensive developer, less time to build a solution with, it must be good for the project.  Of course, over time, lots of counter examples have cropped up: just throw ârails performance bottleneckâ or âentity framework SQL failâ into google and read to learn what happens when developer magic sauce is spread liberally and allowed to determine the architecture.</p>

<p>A single instance of Bede&rsquo;s wallet can generate in the region of 10Gb data / day. It turns out that when you need to keep everything, and the product is growing daily, managing an additional 10Gb of data every day can be moderately painful.  Painful to the extent that we have an operations team, one of whose key roles is essentially to keep everything running.  Over the last year or so weâve scaled vertically, <a href="http://en.wikipedia.org/wiki/2147483647">run out of 32-bit integers</a>, added lots of database nodes, added data centres and strategised about archiving operational data.</p>

<p>Turns out I had fallen victim to the most common of easy vs simple fails.  In architecting the original product, we focussed on tools with which we were familiar - those that were close at hand; and therefore easy for the developer to use.  In this case MySql.  Now, MySql is extremely capable of scaling to massive data volumes, itâs currently powering numerous huge databases like Google Adwords and Facebook <a href="http://thenextweb.com/dd/2014/03/27/facebook-google-linkedin-twitter-launch-webscalesql-custom-version-mysql-massive-databases/">albeit in a much customised form</a>.  But scaling traditional RDBMs does come with a significant ops overhead.  For Bede&rsquo;s wallet, the data architecture at the code level is now pretty mature, we almost never add new data fields.  But as a business, we spend a lot of time working with the data at the persistence level - just to keep the lights on and the replicas fresh.</p>

<p>On reflection, it seems that we chose a persistence technology ignorant of the devops 80-20 rule.  Iâd estimate that to date, of all the many, many man-months of time Bede&rsquo;s IT department has spent building and maintaining this product on MySql, about 20% of that time (if not less) was spent by developers building the original product, during which we benefitted from the wealth of developer tools and documentation at our disposal - it was easy to do.  At least 80% of the time, and therefore cost, has been spent by the operations team, keeping things going.</p>

<p>With my <a href="http://www.infoq.com/presentations/Simple-Made-Easy-QCon-London-2012">Simple made Easy</a> hat on, and my 20/20 hindsight goggles engaged, it was short-sighted to select the easy, comfortable technology, the one that we had experience with, without understanding how the total cost of ownership (TCO) for the decision would be contained mostly in maintenance down the line, rather than the comparatively minimal initial build.</p>

<p>So what else can we do? I think the main learning point has been to select technology with a stronger consideration for TCO.  A less smooth developer experience may well be preferable to more complex operational maintenance strategy. The persistence marketplace these days is awash with distributed database solutions with significantly improved cluster management and auto-healing capabilities, offering different types of storage and varying levels of consistency.  Some of them <a href="https://foundationdb.com/">even support ACID</a>.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Introducing Bede Engineering]]></title>
    <link href="http://engineering.bedegaming.com/blog/2014/10/15/introducing-engineering-dot-bedegaming-dot-com/"/>
    <updated>2014-10-15T17:13:05+00:00</updated>
    <id>http://engineering.bedegaming.com/blog/2014/10/15/introducing-engineering-dot-bedegaming-dot-com</id>
    <content type="html"><![CDATA[<p>A long time in the hoping, not so long in the making (thanks to <a href="http://octopress.org">Octopress</a> and <a href="https://github.com/wallace/justin-kelly-theme">Justin Kelly&rsquo;s Theme</a>), we&rsquo;re pretty excited to finally be able to show you our new engineering microsite.</p>

<p>We&rsquo;ve got some great posts lined up: everything from how we manage our army of servers to our approach to continuous delivery. In the meantime, you can browse some of our open source software using the links on the right.</p>
]]></content>
  </entry>
  
</feed>
