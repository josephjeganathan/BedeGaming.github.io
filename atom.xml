<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Bede Engineering]]></title>
  <link href="http://engineering.bedegaming.com/atom.xml" rel="self"/>
  <link href="http://engineering.bedegaming.com/"/>
  <updated>2014-12-03T13:29:00+00:00</updated>
  <id>http://engineering.bedegaming.com/</id>
  <author>
    <name><![CDATA[Bede Gaming Ltd]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Waste In Software Development]]></title>
    <link href="http://engineering.bedegaming.com/blog/2014/12/01/waste-in-software-development/"/>
    <updated>2014-12-01T16:49:00+00:00</updated>
    <id>http://engineering.bedegaming.com/blog/2014/12/01/waste-in-software-development</id>
    <content type="html"><![CDATA[<p>One of several interesting areas to come out of our tour of Nissan in Sunderland today was how they classify wastage into seven different categories</p>

<ol>
<li><strong>Over-Production</strong>: Making more cars than you need is expensive. you used more people, and now you have to store them somewhere. In the past large car companies might be paying a farmer for use of fields to store the vehicles in until they could be sold. The long term storage is doubly damaging, as rodents tend to love making their homes in the vehicles</li>
<li><strong>Inventory or Stock</strong>: Again, <!-- more --> having more parts in inventory than required takes up storage space, and you may already have paid for the materials. At best, you&rsquo;ve paid too soon, at worst those items may never be required.</li>
<li><strong>Transportation</strong>: This is a big one for manufacturing. Any time you move anything anywhere it costs you money. This could be between factories, where fuel costs add up and traffic delays can ruin your scheduling, or it could be within the factory, where a worker has to cover a part of the floor to get a tool or component. Nissan (and Toyota) take this very seriously. As manufacturing has predictable material costs and value of product, they can actually put a cost &ldquo;per worker footstep&rdquo; to every action within the business. Saving 6-10 footsteps for a process could save thousands of pounds per year</li>
<li><strong>Non Value Adding</strong>: For example legal or safety processes. These things are generally mandatory</li>
<li><strong>Idle Time</strong>: Time waiting for the next item to be delivered to at your workstation is time that does not add value. In the world of manufacturing this is more opportunity to reduce the number of people required for a workstation</li>
<li><strong>Operator Motions</strong>: Bending over to pick stuff up, twisting in under a hood, clambering into the cabin to screw in bolts, or two people working on achieving a single task. Nissan have some really awesome solutions to these problems, for example; instead of scrambling into the cabin to tighten bolts (and probably injure yourself on all the various spiky and sharp edges), they now slide into the cabin on a machine mounted seat that can swivel in and out as the car moves down the line</li>
</ol>


<p><img class="center" src="http://engineering.bedegaming.com/images/nissan-chair.jpg" title="Nissan sliding chair device" alt="Nissan sliding chair device"></p>

<ol>
<li><strong>Poor Quality</strong>: Obvious enough, and one most people are familiar with, but having to fix an item already through the production line is firstly rework, and secondly slower than if it was originally done correctly. Each quality issue is one less car that can go out the factory doors that day. I do find it interesting that its at the bottom of the list for Nissan. They&rsquo;ve obviously removed a lot of the occurrences of this to the point where it is maybe not their most pressing problem</li>
</ol>


<p>I&rsquo;ve been thinking on the differences between what we (software developers) do, and what Nissan (manufacturing) does. Off-the-cuff comments after the tour among colleagues suggested that yes, we probably suffered from at least three of these, but because we are writing software we cannot overproduce, and we don&rsquo;t hold inventory or stock.</p>

<p>On closer reflection though, I think that there are clear parallels between the two industries. Here is my take on an equivalent &ldquo;seven wastes&rdquo;</p>

<ol>
<li><strong>Over-Production</strong>: The feature that was implemented but not asked for, the feature that was demanded but never used, and&hellip;here&rsquo;s the kicker; over-engineering. Some examples are &ldquo;the performance improvement that was not required&rdquo; and &ldquo;the N-tier-highly-scalable-plugin-architecture-driven-workflow-system for the five person internal admin application&rdquo;. These are all examples of work being done that did not result in monetary value being added to the business. How many times have you heard &ldquo;its a cool feature all right, no one <em>uses</em> it, but it is cool.</li>
<li><p><strong>Inventory</strong>: We don&rsquo;t have inventory though, right? Sure we do. Partially completed features on pause due to something else being today&rsquo;s most pressing concern, half-migrated database systems, licenses for products never used. It&rsquo;s all virtual &ldquo;stock&rdquo; or <em>work in progress</em>. Someone has produced a part of a thing, and that thing has not yet been put together.</p>

<blockquote><p><em>&ldquo;Work in progress is a real killer&rdquo;</em></p>

<p>From Nissan&rsquo;s talk on manufacturing wastage</p></blockquote></li>
<li><p><strong>Transportation</strong>:This is the one that I had to think about longest and hardest. In the virtual world we don&rsquo;t really &ldquo;transport&rdquo; goods, and generally data-transfer costs are pretty negligible. True, if you are moving data between two locations that have really slow connections, and the connections are flaky, but this is not really a fair comparison with the manufacturing version. Transportation is about moving between two factories or workstations, our example on reliable connections above would more be akin to reliable power and conveyor belts. Instead, perhaps the time taken to deploy and prepare environments for QA might be a better example, as we are moving between the software equivalents of workstations - states of a work item. If deployment takes a long time, or worse, you have to spend time manually reseting your QA environment to a &ldquo;known good&rdquo;, then this is time when you are trying to move the item between &ldquo;in development&rdquo; and &ldquo;in QA&rdquo;. Its neither one nor the other. We would say it was &ldquo;transitioning&rdquo;.</p></li>
<li><strong>Non-value adding</strong>: The same comments on legal processes apply equally to software development. Data protection/privacy and PCI compliance being common ones. In the online gaming world we tend to have things like &ldquo;Know your customer&rdquo; (understanding if multiple user accounts are really on real person) that we need to do to be good netizens, but don&rsquo;t directly add to the bottom line. Of course, in many if not all &ldquo;non-value adding&rdquo; requirements, they generally do actually add a form of value, called <em>goodwill</em>. If you are seen to a fair player, good safety record or whatever, then people have a tendency to put their trust in you, rather than your competitor. Its very hard to measure the direct impact. You could also argue that legal requirements are worth the <em>entire value of your company</em> if someone is going to shut you down if you don&rsquo;t comply ;)</li>
<li><strong>Idle Time</strong>: It&rsquo;s not too hard to see this one. Team city build times. Deployment times between environments. How long <em>does</em> your machine take to load visual studio anyway ;). What about waiting for a firewall change to be put in place by ops for a new service you&rsquo;ve just written and want to deploy to your dev environment for the first time? Are you going to switch task for the five minutes it takes (or 20 if you are still deploying Azure Cloud Services). A lot of this time is just dead, because your choices are to continue to focus on the task at hand (i.e. do nothing for x minutes) or to context-switch to something else. Since a lot of intellectual tasks can take fifteen plus minutes to get into, and fifteen to get out of again, you&rsquo;re not going to do too well here! (Also, you&rsquo;ve just introduced new <em>work in progress</em>).</li>
<li><strong>Operator Motions</strong>: Manually refactoring all the namespaces of classes in a folder, adding &ldquo;begin method&rdquo; and &ldquo;end method&rdquo; logging to classes, opening the azure portal and clicking the &ldquo;connect&rdquo; option to download an RDP file, before opening a password store to find the unique username/password details for that machine, these are all examples of &ldquo;motions&rdquo; that waste potentially significant amounts of time, repeatedly.</li>
<li><strong>Poor Quality</strong>: Definitely a distinct bane of the current software industry, manufacturing definitely has us there. Again, the double whammy of redoing something already done, and the fact that you have to context switch to do it/might need to work outside your normal delivery process makes this a bitter pill</li>
</ol>


<p>So there you go! Perhaps software engineering is not that different from manufacturing. If these wastage points can all be found to have equivalents, then maybe its far too soon to say &ldquo;but manufacturing is different because of all the predictability&rdquo;. Perhaps its just because we aren&rsquo;t very good at predicting yet&hellip;</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[BedeGaming Puppet Module for Redis]]></title>
    <link href="http://engineering.bedegaming.com/blog/2014/11/24/puppet-redis-module/"/>
    <updated>2014-11-24T16:30:00+00:00</updated>
    <id>http://engineering.bedegaming.com/blog/2014/11/24/puppet-redis-module</id>
    <content type="html"><![CDATA[<p>As of last week we&rsquo;ve created and released a Puppet Module for Redis.  While there are other Redis modules available on GitHub and the Forge, we think a lot of them are either overly complex or outdated in their design and methods.  Many of them also install from source packages, which we don&rsquo;t like.</p>

<!-- more -->


<p>We think our module is a bit better:</p>

<ul>
<li>Simple, clean layout</li>
<li>Offers single entry point (the &lsquo;::redis&rsquo; class)</li>
<li>Provides a full set of sane defaults</li>
<li>Provides for all configuration options found in the redis.conf file</li>
<li>Does all the basic installation, configuration and management you&rsquo;d expect</li>
</ul>


<p>One of the other major reasons for our own module was our desire to not use Redis that came from source packages.  We use CentOS for the Linux portion of our platform, and are pretty religious about only installing from RPM&rsquo;s.  This module expects that there will be a Redis RPM package available somewhere within the yum repos you&rsquo;ve made available on your systems, which we feel is good design, as it leaves it up to you to implement that package source.  That&rsquo;s not the job of a Redis module.</p>

<p>Currently the Redis module is not on the Forge, but probably will be in the near future.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[BedeGaming Puppet Module for FoundationDB]]></title>
    <link href="http://engineering.bedegaming.com/blog/2014/11/18/puppet-foundationdb-module/"/>
    <updated>2014-11-18T16:30:00+00:00</updated>
    <id>http://engineering.bedegaming.com/blog/2014/11/18/puppet-foundationdb-module</id>
    <content type="html"><![CDATA[<p>Here at Bede we&rsquo;ve been using <a href="https://foundationdb.com/">FoundationDB</a> for some time, and are basically in love with it.  Fully distributed, ACID compliant transactions?  Yes please.  It&rsquo;s fast, it scales, it&rsquo;s reliable and redundant.  From an operations persons point of view it&rsquo;s simply sexy.</p>

<!-- more -->


<p>However, it is a relatively new technology, with a small but growing community.  That means that the ecosystem surrounding FDB is not quite as extensive as many of the other, longer lived persistence technologies.  Therefore there was no Puppet modules available to manage installation and configuration, so we had to write our own.</p>

<p>The <a href="https://github.com/BedeGaming/puppet-foundationdb">module</a> can manage installation, configuration, upgrading, etc.  All the usual bits&#8217;n&#8217;bobs you&rsquo;d expect a Puppet module to manage.  This does come with one caveat however:  it doesn&rsquo;t currently manage FDB cluster membership, due to the way FDB itself manages membership.  We&rsquo;re still exploring ways to add at least some amount of membership management into the module, and of course if anyone wants to contribute towards the module, feel free to fork and issue PR&rsquo;s.</p>

<p>The FoundationDB module can be found on the <a href="https://forge.puppetlabs.com/bedegaming/foundationdb">Forge</a>.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Bede Gaming Sponsors Biggest Hackathon in the North East]]></title>
    <link href="http://engineering.bedegaming.com/blog/2014/11/13/bede-sponsors-hackne/"/>
    <updated>2014-11-13T09:20:08+00:00</updated>
    <id>http://engineering.bedegaming.com/blog/2014/11/13/bede-sponsors-hackne</id>
    <content type="html"><![CDATA[<p>Billed as <a href="http://http://www.chroniclelive.co.uk/news/local-news/newcastle-set-north-easts-biggest-8052017">“The biggest public hackathon ever held in the North East”</a>, <a href="http://hackne.com">Hack NE</a>, for Bede, was an ideal opportunity to get our name known in the community.  With a largely student based attendee list, people had come from as far away as London to compete. With free t-shirts, face cloths, breath mints, wet wipes and swag bags, Bede&rsquo;s branded 8Gig USB sticks looked a good addition for those brave enough to come talk to us.</p>

<!-- more -->


<p>As co-sponsor, we set a challenge for the competing teams. Bede supplied a Kafka service to publish a real-time event stream of messages about deposits, withdrawals and winners for a mock gaming website. We challenged the Hackers to consume the messages and create something beautiful.</p>

<h3>Day 1, 9AM</h3>

<p>With the hackers seated in the halls of the Hancock museum, and ready to start, Bede MD Dan Smyth took to the podium to deliver an inspired speech about Bede and an introduction to our challenge. This was followed by 5 other sponsors. All told there were 5 prizes on offer, including the actual Hack NE overall champion.</p>

<p>Representing the tech side of Bede were: Mark Radford, Daniel Lackenby, Amila Prabandhika, Richard Thompson and Anton Jidkov, with Andy Thompson fielding questions about the company and careers opportunities. As the teams started work on whose services they would use, a few nervous hackers approached us and asked for more details on the service. It seemed that with a prize of £100 Amazon vouchers per team member, we had their interest.</p>

<p>By the time the Bede techies had retired for the day, three teams of hackers had incorporated our challenge into their projects, using Java and Ruby Kafka clients respectively to consume the data we had made available. Just from walking around the room and assisting where we could to get teams up and running with the data there was no question that some cool hacks were being undertaken using Bede’s service as well as teams that had gone for their own ideas. We left them to their night of caffeine and code.</p>

<h3>Day 2, 7AM</h3>

<p>The room of hackers had been whittled down to a hardy few, breakfast was being served.
A slight panic had arisen at 3am, the Kafka service has stopped responding to requests…
A restart of the service had it working again so all was not lost for the teams that had pushed through.
Bede USB Sticks all gone, loads of SendGrid T-shirts left.</p>

<h3>Day 2 9AM</h3>

<p>Presentations were to be done in the Newcastle Students Union.
In total, 8 teams presented with 6 having a finished, working product.
Each sponsor gets to award their prize to the team they liked best with the overall prize being awarded by MLH.
The best presentations were:
Stockcruiser - a fantastic visual representation of organically created cars that ran along a track. The track was generated by using data from the Bloomberg API with the car jumping based on Bede&rsquo;s winners feed and power ups appearing with deposits.</p>

<p><img class="center" src="http://engineering.bedegaming.com/images/hack-stockcruiser.jpg" title="Stock Cruiser Presentation" alt="Stock Cruiser Presentation"></p>

<p>Metro Apologises - Using the Metro information boards as a theme, they showed the Winners there and took the Bloomberg stocks figures to show a cartoon metro train derailing itself (or other reactions depending on the size of the figures).
BloomBedeGridMachine - Using an Arduino board and an LED Ticker Grid, The Bede winners ticked across the Grid and then showed a graph of the winning amounts over a time period. Then, a click of a remote control and the Feed showed Stock prices from the Bloomberg API.
<img class="center" src="http://engineering.bedegaming.com/images/hack-crablab.jpg" title="Crablab present BloomBedeGridMachine" alt="Crablab present BloomBedeGridMachine"></p>

<p>A quick conflab with the other sponsors and we each decided our winners. Bede awarded its prize to the BloomBedeGridMachine.</p>

<p><img class="center" src="http://engineering.bedegaming.com/images/hack-handshake.jpg" title="Bede Congratulate the Winners" alt="Bede Congratulate the Winners"></p>

<p>Despite presenting on a refreshments trolley, they had worked extremely well as a team, each taking a single task on with one team member linking all the parts together and project managing.
One team member is quoted as saying “That Kafka software is awful to integrate with”.</p>

<p>We had a lot of enquires about Bede as a prospective employer and if we take summer/year long interns. All in all, Bede has projected a positive message to the local tech community and looks forward to hosting more hackathons in the future.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[CD in action at Nissan Sunderland]]></title>
    <link href="http://engineering.bedegaming.com/blog/2014/11/06/cd-in-action-at-nissan-sunderland/"/>
    <updated>2014-11-06T12:54:14+00:00</updated>
    <id>http://engineering.bedegaming.com/blog/2014/11/06/cd-in-action-at-nissan-sunderland</id>
    <content type="html"><![CDATA[<p>The Nissan UK car plant at Sunderland produces almost as many cars every year as Italy’s entire automative industry. It’s a mammoth site.  Each of the four production lines in this factory is capable of producing one car every minute, continuously. As in 24x7x365. True continuous delivery into production. I was lucky enough to be invited on a factory tour by the good people at the <a href="http://www.entrepreneursforum.net">entrepreneurs forum</a> recently. It was fascinating to see how Nissan have engineered every aspect of production to minimise waste and keep the line flowing. At Bede I&rsquo;ve spent a lot of my time trying to enable agile teams to deliver high quality software into production as fast as possible, so after the factory tour my mind was left reeling with comparisons between Nissan and Bede&rsquo;s approaches to Continuous Delivery.</p>

<p><img class="center" src="http://engineering.bedegaming.com/images/nissan-plant.jpg" title="Aerial view of Nissan UK plant at Sunderland" alt="Aerial view of Nissan UK plant at Sunderland">
<em>Source: <a href="http://www.themanufacturer.com/articles/nissan-smashes-uk-output-record-at-sunderland-plant/">http://themanufacturer.com</a></em></p>

<!-- more -->


<p>I&rsquo;ve visited a few factories in a previous life, but I&rsquo;ve never visited a car production line: it&rsquo;s quite something to behold. Chassis are on a continuously moving conveyer, separated by a few feet, and move along the factory floor passing a succession of workstations.  The production conveyer moves at a constant speed - every work station has 60 seconds to perform its assigned tasks.  Some workstations have a single task to perform, others fit multiple parts to the chassis. Larger jobs are split up between multiple work stations.  Everything possible is done to ease the job of the fitter.  This is done by minimising the physical movements required, minimising risk of a line stoppage, reducing waste and maximising the amount of useful work that can be done in 60 seconds.</p>

<p><img class="center" src="http://engineering.bedegaming.com/images/nissan-line.jpg" title="Nissan UK Qashqai production line" alt="Nissan UK Qashqai production line">
<em>Source: <a href="http://petrolblog.com/2012/05/rising-sunderland-a-british-success-story/">http://petrolblog.com/</a></em></p>

<p>Some rambling thoughts from the visit:</p>

<h3>Shared Vision</h3>

<p>Nissan are big on shared vision. Our tour guides, both ex Nissan employees, bleed Nissan. It was clear that they understood Nissan&rsquo;s vision and were proud to be associated with them. Nissan work hard to install a sense of shared values in their staff. Information radiators are everyone throughput the plant - both static and display screens.  The primary metric on the shop floor is efficiency - which seems to be the number of cars rolling off the line compared to target.  On the day I visited the plant was running at 108% efficiency. A similar metric for Bede might be the number of successful production deployments achieved in a given time period.  Right now I&rsquo;d estimate we push out 5-10 builds into production each week.</p>

<p>Despite employees showing a strong sense of Nissan pride, they know that efficiency relative to other plants will determine whether Sunderland receives future car models for manufacture, implying expansion and job security. This presents an interesting dichotomy - staff are passionate about Nissan as a brand, but have a local basis - they are in direct competition with other global Nissan car plants to ensure long term security.  Interestingly, Bede has 3 software development offices - Newcastle, London and Sofia.  We&rsquo;ve worked hard to break down inter office rivalries, and have many product teams that span at least one office boundary.  In this sense, Bede&rsquo;s world of bits frees it from Nissan&rsquo;s physical limitations in terms of delivery across a distributed estate.</p>

<h3>Continuous, relentless delivery to production</h3>

<p>Production workers understand that nothing can be allowed to stop the line. It&rsquo;s the shared responsibility of every employee to do whatever it takes to minimise downtime.  I heard that stoppages cost something like £10,000 per minute. This has two separate parallels in the software world.  Firstly, the production effort - keeping the build green, ensuring that only quality builds are deployed into environments. Through careful application of continuous integration, testing and sandbox deployments, especially with Bede&rsquo;s SOA, we strive to minimise the amount of time that the line is down (e.g. environments are broken). We&rsquo;ve recently added an isolated automation testing environment at the head of our CI pipeline, to perform smoke tests on builds before automatically deploying into our first visible development environment. This increases the overall stability of the development environment at the cost of adding some time between commits being available for developer testing. We opted to make this trade off to focus on stability, since multiple product teams shares a common development environment.</p>

<p><img class="center" src="http://engineering.bedegaming.com/images/octopus-dashboard.png" title="Continuous Integration Dashboard" alt="Continuous Integration Dashboard"></p>

<p>Secondly, uptime in production - Bede manages the production environments for its clients, so relentless monitoring of servers and applications is required to keep the status green and exceed stated SLA uptimes. Of course Nissan&rsquo;s relationship with their product continues long after delivery too, though a most shared approach for managing that client relationship exists in the form of dealerships.</p>

<p><img class="center" src="http://engineering.bedegaming.com/images/ops-nr-dashboard.jpg" title="Environment Monitoring" alt="Environment Monitoring"></p>

<h3>QA</h3>

<p>Quality Assurance at the Nissan plant boils down to accountability.  As each chassis passes a workstation, the fitter stamps a card (yes, a physical piece of paper) with their own personalised stamp. In this way they&rsquo;re taking direct responsibility for the quality of the work they are performing. The card forms part of the permanent history of the car, it is never destroyed. As a result, fitters must take responsibility for their work.  Dedicated Quality Assurance staff do exist in the plant, but their job exists to catch unforeseen errors. I like the idea of producers being so closely linked to the produced artifacts. We already have the commit data for every release, but we don&rsquo;t publicise it internally at the moment, this is something I&rsquo;m going to mull over&hellip;  I do think that as our usage of automation testing improves, so our testers are freed from having to spend the majority of their time writing automation suites, and can focus more on exploratory testing, like the Nissan QAs.</p>

<p><img class="center" src="http://engineering.bedegaming.com/images/bt-commiters.png" title="Commit statistics for a Bede component" alt="Commit statistics for a Bede component"></p>

<h3>Kaizen</h3>

<p>Kaizen is a fancy word for continuous improvement. Key to this is accepting that process nirvana is an unachievable state, but that there is always something that can be done to move you closer to perfection. Suggestions for process improvement are grass roots as well as management driven. I think we can say the same for Bede - after working hard on Agile process, we are starting to find that team members initiate as much process change as managers. We&rsquo;ve worked hard to create a <a href="https://hbr.org/2013/01/to-increase-innovation-take-th/">smart-fail</a> culture, where employees feel confident to try things out.  Nissan don&rsquo;t offer incentives for improvements. An employee could suggest an improvement that saves the plant 1% of its running costs, but the staff member won&rsquo;t see a penny of that. At first I thought this was backward - why not incentivise staff to suggest improvements; but perhaps Nissan have nailed the culture so well that staff see it as their duty to continuously improve process.</p>

<h3>Leverage your bottlenecks</h3>

<p>At one particular work centre, the chassis lifts up and passes overhead so that fitters can tighten up some bolts on the underside of the vehicle. The air tool used for this job is obviously very heavy, it used to be a difficult job and production managers complained of fatigue and minor injury rates at the workstation. Staff suggested building a semi-robotic arm, essentially taking the weight of the tool, but allowing the operator to position it as necessary. The plant&rsquo;s internal engineering team obliged, and the problem is now solved. This is a great example of leveraging the bottleneck at this workstation. For more on bottlenecks and constraints theory, see the reading recommendations at the end of this post. The obvious comparison in the world of bits is automation. Reducing repetition, with its accompanying opportunities for mistakes and time wastage.</p>

<h3>Staff Liquidity</h3>

<p>Nissan has a dedicated training academy on site, in partnership with a local college.  The main goal of training is to get new employees up to the point that they can effectively perform at least 3 different workstation tasks to an acceptable level - staff are rotated frequently, even within shifts.  This kind of staff liquidity ensures that when there&rsquo;s a bout of flu going around, the production line doesn&rsquo;t grind to a halt - there are others trained to pick up the slack in any workstation. If things get desperate, line supervisors and managers are expected to get down to the shop floor and keep things running.</p>

<p>Liquidity is something that Bede software teams are still working to improve.  We&rsquo;ve removed as many dependencies on specific individuals as possible, but there isn&rsquo;t yet perfect liquidity. Paul has blogged previously on this subject, in <a href="http://engineering.bedegaming.com/blog/2014/10/16/who-is-your-brent/">Who is your brent</a>. I think the KPI for staff liquidity is when we proactively move &lsquo;key&rsquo; staff between teams. This has always been a long term aim - keeping engineers fresh by moving them around and exposing them to new problems, helping good ideas and practices to pollinate between teams, and further increasing liquidity.</p>

<p>Enjoyed this article? You should probably read <a href="http://www.amazon.co.uk/The-Phoenix-Project-Helping-Business-ebook/dp/B00AZRBLHO">The Phoenix Project</a>, or even better, go back to the source with <a href="http://www.amazon.co.uk/Goal-Process-Ongoing-Improvement-ebook/dp/B002LHRM2O/ref=sr_1_1?s=digital-text&amp;ie=UTF8&amp;qid=1415278766&amp;sr=1-1&amp;keywords=the+goal">The Goal</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Modelling an nginx Application Proxy using Puppet and Hiera]]></title>
    <link href="http://engineering.bedegaming.com/blog/2014/11/05/modelling-an-nginx-application-proxy-using-puppet-and-hiera/"/>
    <updated>2014-11-05T15:53:08+00:00</updated>
    <id>http://engineering.bedegaming.com/blog/2014/11/05/modelling-an-nginx-application-proxy-using-puppet-and-hiera</id>
    <content type="html"><![CDATA[<h1>Goal</h1>

<p>To model nginx configurations in Hiera, extracting those configurations from the Puppet DSL, and create a Puppet Profile to combine that with the nginx module.</p>

<!-- more -->


<h1>Links</h1>

<h2>Puppet Docs</h2>

<ul>
<li><a href="https://docs.puppetlabs.com/learning/ral.html">Puppet Resource Abstraction Layer</a></li>
<li><a href="https://docs.puppetlabs.com/references/latest/function.html#createresources">Puppet create_resources</a></li>
<li><a href="https://docs.puppetlabs.com/guides/scope_and_puppet.html">Scoping</a></li>
<li><a href="https://docs.puppetlabs.com/puppet/latest/reference/lang_namespaces.html">Namespacing</a></li>
</ul>


<h2>Puppet Roles/Profiles</h2>

<ul>
<li><a href="http://www.slideshare.net/PuppetLabs/roles-talk">Craig Dunn, Designing Puppet Talk</a></li>
<li><a href="https://ask.puppetlabs.com/question/1655/an-end-to-end-roleprofile-example-using-hiera/">End to End Roles and Profiles Example</a></li>
<li><a href="http://garylarizza.com/blog/2014/02/17/puppet-workflow-part-1/">Puppet Workflow Part 1</a></li>
<li><a href="http://garylarizza.com/blog/2014/02/17/puppet-workflow-part-2/">Puppet Workflow Part 2</a></li>
</ul>


<h2>Hiera</h2>

<ul>
<li><a href="https://docs.puppetlabs.com/hiera/1/">Puppet Labs Hiera Docs</a></li>
<li><a href="https://docs.puppetlabs.com/hiera/1/variables.html#passing-variables-to-hiera">Passing Variables to Hiera</a></li>
</ul>


<h2>nginx Module</h2>

<ul>
<li><a href="https://github.com/jfryman/puppet-nginx">jfryman nginx Puppet Module</a></li>
</ul>


<h2>nginx</h2>

<ul>
<li><a href="http://wiki.nginx.org/Main">nginx Project Page</a></li>
</ul>


<h1>Requirements</h1>

<p>Within nginx we need to define a set of nginx &ldquo;server&rdquo; contexts with the
same set of &ldquo;location&rdquo; contexts in each &ldquo;server&rdquo;.</p>

<p>Think of this as &ldquo;<a href="http://SiteA.com">http://SiteA.com</a>&rdquo; and &ldquo;<a href="http://SiteB.com">http://SiteB.com</a>&rdquo;, that both
have the same set of &ldquo;locations&rdquo;, which define the nginx upstreams
(backends), that combined provide a single site that is created from
disparate SOA applications.</p>

<p>This is essentially a model to build a nginx based proxy layer sitting
in front of a multi-tenant SOA application stack.</p>

<h2>Approach</h2>

<p><em>Example 1: Single Server, Two Locations modelled in Hiera (YAML)</em></p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>proxy::sites::vhosts:
</span><span class='line'>  SiteA:
</span><span class='line'>    listen_port : 8080
</span><span class='line'>    rewrite_to_https : false
</span><span class='line'>    use_default_location : false
</span><span class='line'>
</span><span class='line'>proxy::sites::locations:
</span><span class='line'>  root:
</span><span class='line'>    vhost : SiteA
</span><span class='line'>    location : '/'
</span><span class='line'>    ensure : 'present'
</span><span class='line'>    proxy : 'http://serviceA'
</span><span class='line'>  server_status: 
</span><span class='line'>    vhost : SiteA
</span><span class='line'>    location : '/server-status'
</span><span class='line'>    ensure : 'present'
</span><span class='line'>    stub_status : true</span></code></pre></td></tr></table></div></figure>


<p>In this example we have a single &ldquo;server&rdquo;, called SiteA. SiteA also has 2 locations defined, &ldquo;root&rdquo;, and &ldquo;server-status&rdquo;.</p>

<p>The relationship between the server and location is defined by the parameter &ldquo;vhost&rdquo; in the location stanza; by being set to &ldquo;SiteA&rdquo;, the location stanza is created within the SiteA server stanza, when all this is realized into an actual nginx configuration file.</p>

<p>There are possibly other Hiera/YAML structures that would allow us to
model this relationship more clearly, however we&rsquo;re using this specific
structure because we want to take advantage of Puppets
<code>create_resources</code> function in conjunction with the nginx module:</p>

<ul>
<li><a href="https://docs.puppetlabs.com/references/latest/function.html#createresources">https://docs.puppetlabs.com/references/latest/function.html#createresources</a></li>
</ul>


<p>Essentially, with the data structured in the correct manner we can pass
it to <code>create_resources</code> as a Puppet hash and it will create the
specified resource. In this case the specific resources are the location
and vhost resources defined in the nginx module. By defining our config
data in Hiera in the right structure, we can use <code>create_resources</code> and
make our life a bit simpler.</p>

<p>This presents a challenge when you want to create more than one server
(multiple vhosts).</p>

<p><em>Example 2: Two vhosts, Two locations</em></p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>proxy::sites::vhosts:
</span><span class='line'>  SiteA:
</span><span class='line'>    listen_port : 8080
</span><span class='line'>    rewrite_to_https : false
</span><span class='line'>    use_default_location : false
</span><span class='line'>  SiteB:
</span><span class='line'>    listen_port : 8080
</span><span class='line'>    rewrite_to_https : false
</span><span class='line'>    use_default_location : false
</span><span class='line'>
</span><span class='line'>proxy::sites::locations:
</span><span class='line'>  root:
</span><span class='line'>    vhost : SiteA
</span><span class='line'>    location : '/'
</span><span class='line'>    ensure : 'present'
</span><span class='line'>    proxy : 'http://serviceA
</span><span class='line'>  server_status:
</span><span class='line'>    vhost : SiteA
</span><span class='line'>    location : '/server-status'
</span><span class='line'>    ensure : 'present'
</span><span class='line'>    stub_status : true</span></code></pre></td></tr></table></div></figure>


<p>You now have 2 servers/vhosts. However the location stanzas are only
related to the first server/vhost (SiteA), as specified by the locations
vhost paramater.</p>

<p>In order to create a &ldquo;root&rdquo; and &ldquo;server_status&rdquo; location for SiteB,
following the same model as above, you would end up with:</p>

<p><em>Example 3: Two vhosts, Four locations (2 per vhost)</em></p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>proxy::sites::vhosts:
</span><span class='line'>  SiteA:
</span><span class='line'>    listen_port : 8080
</span><span class='line'>    rewrite_to_https : false
</span><span class='line'>    use_default_location : false
</span><span class='line'>  SiteB:
</span><span class='line'>    listen_port : 8080
</span><span class='line'>    rewrite_to_https : false
</span><span class='line'>    use_default_location : false
</span><span class='line'>
</span><span class='line'>proxy::sites::locations:
</span><span class='line'>  SiteA_root:
</span><span class='line'>    vhost : SiteA
</span><span class='line'>    location : '/'
</span><span class='line'>    ensure : 'present'
</span><span class='line'>    proxy : 'http://serviceA
</span><span class='line'>  SiteA_server_status:
</span><span class='line'>    vhost : SiteA
</span><span class='line'>    location : '/server-status'
</span><span class='line'>    ensure : 'present'
</span><span class='line'>    stub_status : true
</span><span class='line'>  SiteB_root:
</span><span class='line'>    vhost : SiteB
</span><span class='line'>    location : '/'
</span><span class='line'>    ensure : 'present'
</span><span class='line'>    proxy : 'http://serviceA
</span><span class='line'>  SiteB_server_status:
</span><span class='line'>    vhost : SiteB
</span><span class='line'>    location : '/server-status'
</span><span class='line'>    ensure : 'present'
</span><span class='line'>    stub_status : true</span></code></pre></td></tr></table></div></figure>


<p>This is obviously suboptimal as you&rsquo;re repeating configuration for both
locations now. For each vhost SiteA and SiteB, you need to define 2
locations.</p>

<p>You&rsquo;ll also notice that the name of the locations have now changed to
&ldquo;SiteA_root&rdquo;, &ldquo;SiteA_server_status&rdquo; and &ldquo;SiteB_root&rdquo;,
&ldquo;SiteB_server_status&rdquo;. This is due to Puppet not allowing duplicate
resource declarations, which these locations would be if they were both
named &ldquo;root&rdquo; and &ldquo;server_status&rdquo;. So we create unique resources, by
making the resource names unique.</p>

<p>You can see where this is leading. For every vhost that we want to add,
that has the same set of locations, we&rsquo;ll end up duplicating the
location data, and just changing the location name and the vhost the
location is associated with. This is probably bad, at least it feels
very bad to me.</p>

<p>The natural response to this is &ldquo;Simples! I&rsquo;ll just iterate over the
list of vhosts and create the set of locations for each server!&rdquo;.</p>

<p>Nope. Not really.</p>

<p>Puppet DSL doesn&rsquo;t really do iteration. Not naturally anyhow.</p>

<p>My favorite comment on this:</p>

<ul>
<li><a href="http://stackoverflow.com/questions/12958114/how-to-iterate-over-an-array-in-puppet/13008766#13008766">http://stackoverflow.com/questions/12958114/how-to-iterate-over-an-array-in-puppet/13008766#13008766</a></li>
</ul>


<p>Quote: &ldquo;The Puppet developers have irrational prejudices against
iteration based on a misunderstanding about how declarative languages
work.&rdquo;</p>

<p>(Disclaimer: I&rsquo;m not a dev, I won&rsquo;t attempt to evaluate the truth of
that statement, but I still think its amusing)</p>

<p>So we have 2 problems:</p>

<ol>
<li>Iteration in Puppet is not… normal, allowed, right, easy?</li>
<li>The &ldquo;names&rdquo; of the locations need to be unique, which means they
can&rsquo;t simply be text labels in YAML. There must be some
interpolation somewhere.</li>
</ol>


<p>We&rsquo;ll deal with the second problem first, as it&rsquo;s a slightly easier
problem to solve, at least in my experience.</p>

<h2>Hiera Interpolation</h2>

<p>Hiera/Puppet allows variables to be passed into Hiera:</p>

<ul>
<li><a href="https://docs.puppetlabs.com/hiera/1/variables.html#passing-variables-to-hiera">https://docs.puppetlabs.com/hiera/1/variables.html#passing-variables-to-hiera</a></li>
</ul>


<p>Quote: &ldquo;When used with Puppet, Hiera automatically receives all of
Puppet&rsquo;s current variables. This includes facts and built-in variables,
as well as local variables from the current scope&rdquo;.</p>

<p>This means we can pass Hiera some variable defined within the Puppet
Manifest, and hopefully therereby creating dynamically named nginx
location resources within Puppet. Probably the most important bit of
that quote is that Hiera has access to &ldquo;local variables from the current
scope&rdquo;. That&rsquo;ll be touched upon further on in this article.</p>

<p>So, that would look something like Example 4.</p>

<p><em>Example 4: Two vhosts, 2 dynamically named locations</em></p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>proxy::sites::vhosts:
</span><span class='line'>  SiteA:
</span><span class='line'>    listen_port : 8080
</span><span class='line'>    rewrite_to_https : false
</span><span class='line'>    use_default_location : false
</span><span class='line'>  SiteB:
</span><span class='line'>    listen_port : 8080
</span><span class='line'>    rewrite_to_https : false
</span><span class='line'>    use_default_location : false
</span><span class='line'>
</span><span class='line'>proxy::sites::locations:
</span><span class='line'>  "%{vhost}_root":
</span><span class='line'>    vhost : "%{vhost}"
</span><span class='line'>    location : '/'
</span><span class='line'>    ensure : 'present'
</span><span class='line'>    proxy : 'http://serviceA
</span><span class='line'>  "%{vhost}_server_status":
</span><span class='line'>    vhost : "%{vhost}"
</span><span class='line'>    location : '/server-status'
</span><span class='line'>    ensure : 'present'
</span><span class='line'>    stub_status : true</span></code></pre></td></tr></table></div></figure>


<p>So, without getting into the intricate details, this suggests that the
nginx location resources will be named <code>&lt;vhost&gt;_&lt;location&gt;</code>. The goal
would be to end up with 4 locations, 2 assigned to each vhost.</p>

<p><em>Example 5: Locations per Vhost</em></p>

<table style="width:100%">
  <tr>
    <th>Vhost</td>
    <th>Location Name</td> 
  </tr>
  <tr>
    <td>SiteA</td>
    <td>SiteA_root</td> 
  </tr>
  <tr>
    <td></td>
    <td>SiteA_server_status</td> 
  </tr>
  <tr>
    <td>SiteB</td>
    <td>SiteB_root</td> 
  </tr>
  <tr>
    <td></td>
    <td>SiteB_server_status </td> 
  </tr>
</table>


<p>The next problem to solve is how to iterate over the list of vhosts.</p>

<h2>Puppet Iteration</h2>

<p>As mentioned, Puppet doesn&rsquo;t really do iteration natively (ignoring the
future parser for now). So how do we accomplish this using native Puppet
DSL?</p>

<p>The first thing to realize is that iteration does in fact happen (or
something similar enough that the difference doesnt matter to most
people). A very good and clear blog article about this can be found
here:</p>

<ul>
<li><a href="https://tobrunet.ch/2013/01/iterate-over-datastructures-in-puppet-manifests/">https://tobrunet.ch/2013/01/iterate-over-datastructures-in-puppet-manifests/</a></li>
</ul>


<p>The basic point being made is that native Puppet functions will iterate
over a Puppet array, executing for each array member.</p>

<p>The first example on that blog post is as follows.</p>

<p><em>Example 6: Iteration in Puppet DSL</em></p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>define arrayDebug {
</span><span class='line'> notify { [Item ${name}]() }
</span><span class='line'>}
</span><span class='line'>
</span><span class='line'>class array {
</span><span class='line'> $array = [ 'item1', 'item2', 'item3' ]
</span><span class='line'> arrayDebug { $array: }
</span><span class='line'>}</span></code></pre></td></tr></table></div></figure>


<p>Essentially the <code>arrayDebug</code> resource (define) will iterate over the
array members of the array <code>$array</code>.</p>

<h2>Creating a Puppet Profile</h2>

<p>So the next step is to write a Puppet &ldquo;Profile&rdquo; for nginx that
encapsulates the functionality we want, using Hiera as the data source,
and the nginx module as the underlying component.</p>

<p>Lets start by creating the basic Hiera config needed for a very simple
nginx install.</p>

<p><em>Example 7: Hiera for nginx</em></p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>nginx::default::mail : false
</span><span class='line'>nginx::default::worker_processes : %{processorcount}
</span><span class='line'>nginx::default::server_tokens : 'off'
</span><span class='line'>nginx::default::nginx_error_log : '/var/log/nginx/error.log debug'
</span><span class='line'>nginx::default::http_access_log : '/var/log/nginx/access.log'
</span><span class='line'>nginx::default::proxy_cache_path : '/var/cache/nginx'
</span><span class='line'>nginx::default::proxy_cache_levels : '2'
</span><span class='line'>nginx::default::proxy_cache_keys_zone : 'cache:10m'
</span><span class='line'>nginx::default::proxy_cache_max_size : '2048m'</span></code></pre></td></tr></table></div></figure>


<p>There&rsquo;s nothing exceptional here, this is all nginx boilerplate to set
some global defaults for nginx. The interesting bit of this is when we
start creating the nginx Profile.</p>

<p><em>Example 8: Base nginx Profile in Puppet DSL</em></p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>class profile::linux::nginx {
</span><span class='line'>
</span><span class='line'>  $mail                           = hiera('nginx::default::mail')
</span><span class='line'>  $worker_processes               = hiera('nginx::default::worker_processes')
</span><span class='line'>  $server_tokens              = hiera('nginx::default::server_tokens')
</span><span class='line'>  $nginx_error_log                = hiera('nginx::default::nginx_error_log')
</span><span class='line'>  $http_access_log                = hiera('nginx::default::http_access_log')
</span><span class='line'>  $proxy_cache_path               = hiera('nginx::default::proxy_cache_path')
</span><span class='line'>  $proxy_cache_levels         = hiera('nginx::default::proxy_cache_levels')
</span><span class='line'>  $proxy_cache_keys_zone      = hiera('nginx::default::proxy_cache_keys_zone')
</span><span class='line'>  $proxy_cache_max_size           = hiera('nginx::default::proxy_cache_max_size')
</span><span class='line'>  $names_hash_bucket_size     = hiera('nginx::default::names_hash_bucket_size')
</span><span class='line'>
</span><span class='line'>  #################################################
</span><span class='line'>  # Create the base nginx config by passing the nginx module the minimum config that we use across all our systems
</span><span class='line'>  #################################################
</span><span class='line'>
</span><span class='line'>  class { '::nginx':
</span><span class='line'>    mail                      =&gt; $mail,
</span><span class='line'>    worker_processes          =&gt; $worker_processes,
</span><span class='line'>    server_tokens                 =&gt; $server_tokens,
</span><span class='line'>    nginx_error_log           =&gt; $nginx_error_log,
</span><span class='line'>    http_access_log           =&gt; $http_access_log,
</span><span class='line'>    proxy_cache_path          =&gt; $proxy_cache_path,
</span><span class='line'>    proxy_cache_levels            =&gt; $proxy_cache_levels,
</span><span class='line'>    proxy_cache_keys_zone         =&gt; $proxy_cache_keys_zone,
</span><span class='line'>    proxy_cache_max_size      =&gt; $proxy_cache_max_size,
</span><span class='line'>    names_hash_bucket_size        =&gt; $names_hash_bucket_size,
</span><span class='line'>  }
</span><span class='line'>}</span></code></pre></td></tr></table></div></figure>


<p>So this is all pretty simple again. This is a Puppet class called
<code>profile::linux::nginx</code>, which sets some default variables, and passes
them to another class called <code>::nginx</code>.</p>

<p>This class is a &ldquo;Profile&rdquo; simply by dint of it being created within the
Profile module / namespace. It&rsquo;s technically no different than any other
Puppet module, it&rsquo;s simply a widely accepted convention that Puppet
Roles and Profiles are modules.</p>

<p>The <code>::nginx</code> class actually refers to the nginx module, denoted by the
leading <code>::</code>, basically meaning &ldquo;at top scope, named nginx&rdquo;.</p>

<p>If you&rsquo;re wondering about the <code>::</code> colon syntax, start by reading about
Puppet scope and namespacing:</p>

<ul>
<li><a href="https://docs.puppetlabs.com/guides/scope_and_puppet.html">https://docs.puppetlabs.com/guides/scope_and_puppet.html</a></li>
<li><a href="https://docs.puppetlabs.com/puppet/latest/reference/lang_namespaces.html">https://docs.puppetlabs.com/puppet/latest/reference/lang_namespaces.html</a></li>
</ul>


<p>So this nginx Profile achieves the very first of our goals; that is to
install nginx and set some very basic global nginx parameters.</p>

<p>The next step would be create the nginx &ldquo;servers&rdquo; (called vhosts here).
In order to achieve this step we need to retrieve the vhost
configuration data from Hiera. We&rsquo;ll then use that data to create the
vhosts.</p>

<p><em>Example 9: nginx Profile with vhosts being created</em></p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>class profile::linux::nginx {
</span><span class='line'>
</span><span class='line'>  $mail                           = hiera('nginx::default::mail')
</span><span class='line'>  $worker_processes               = hiera('nginx::default::worker_processes')
</span><span class='line'>  $server_tokens              = hiera('nginx::default::server_tokens')
</span><span class='line'>  $nginx_error_log                = hiera('nginx::default::nginx_error_log')
</span><span class='line'>  $http_access_log                = hiera('nginx::default::http_access_log')
</span><span class='line'>  $proxy_cache_path               = hiera('nginx::default::proxy_cache_path')
</span><span class='line'>  $proxy_cache_levels         = hiera('nginx::default::proxy_cache_levels')
</span><span class='line'>  $proxy_cache_keys_zone      = hiera('nginx::default::proxy_cache_keys_zone')
</span><span class='line'>  $proxy_cache_max_size           = hiera('nginx::default::proxy_cache_max_size')
</span><span class='line'>  $names_hash_bucket_size     = hiera('nginx::default::names_hash_bucket_size')
</span><span class='line'>
</span><span class='line'>  #################################################
</span><span class='line'>  # Get the hash of vhosts from Hiera. Extract the hash keys into a list (array).
</span><span class='line'>  #################################################
</span><span class='line'>
</span><span class='line'>  $vhosts                     = hiera('proxy::sites::vhosts')
</span><span class='line'>
</span><span class='line'>  #################################################
</span><span class='line'>  # Create the base nginx config by passing the nginx module the minimum config that we use across all our systems
</span><span class='line'>  #################################################
</span><span class='line'>
</span><span class='line'>  class { '::nginx':
</span><span class='line'>    mail                      =&gt; $mail,
</span><span class='line'>    worker_processes          =&gt; $worker_processes,
</span><span class='line'>    server_tokens                 =&gt; $server_tokens,
</span><span class='line'>    nginx_error_log           =&gt; $nginx_error_log,
</span><span class='line'>    http_access_log           =&gt; $http_access_log,
</span><span class='line'>    proxy_cache_path          =&gt; $proxy_cache_path,
</span><span class='line'>    proxy_cache_levels            =&gt; $proxy_cache_levels,
</span><span class='line'>    proxy_cache_keys_zone         =&gt; $proxy_cache_keys_zone,
</span><span class='line'>    proxy_cache_max_size      =&gt; $proxy_cache_max_size,
</span><span class='line'>    names_hash_bucket_size        =&gt; $names_hash_bucket_size,
</span><span class='line'>  }
</span><span class='line'>
</span><span class='line'>  ################################################
</span><span class='line'>  # Create the ngingx vhosts (server blocks in nginx config terms). Pass create_resources the hash retrieved from Hiera,
</span><span class='line'>  # into the nginx::resource::vhost resource defined by the nginx module
</span><span class='line'>  ################################################
</span><span class='line'>
</span><span class='line'>  create_resources('::nginx::resource::vhost', $vhosts)
</span><span class='line'>
</span><span class='line'>}</span></code></pre></td></tr></table></div></figure>


<p>First we add some functionality to retrieve the vhost config from Hiera
using a Hiera lookup function in Puppet:</p>

<pre><code>$vhosts = hiera('proxy::walletv2::vhosts')
</code></pre>

<p>We then pass the resultant hash to a Puppet function called
<code>create_resrouces</code>:</p>

<pre><code>create_resources('::nginx::resource::vhost', $vhosts)
</code></pre>

<p><code>create_resources</code> is a very useful Puppet function. Given the right set
of information, in the right structure, it will auto-magically create
the specified resource. In this case the resource we&rsquo;re talking about is
the <code>::nginx::resource::vhost</code> resource. This resource is defined in the
nginx module, as denoted by the top scope <code>::nginx</code>. The hash <code>$vhosts</code>
contains the data retrieved from Hiera, specifically from the key
<code>proxy::sites::vhosts</code> found in Example 2 to Example 4.</p>

<p>This will create the nginx vhost (server) configurations in the actual
nginx config files, using the key/values as parameters.</p>

<p>Further reading:</p>

<ul>
<li><a href="https://docs.puppetlabs.com/references/latest/function.html#createresources">https://docs.puppetlabs.com/references/latest/function.html#createresources</a></li>
<li><a href="https://docs.puppetlabs.com/learning/ral.html">https://docs.puppetlabs.com/learning/ral.html</a></li>
</ul>


<p>The final step is to combine our interpolated Hiera data and Puppet
iteration learnings into the Profile so that each vhost that gets
created, also gets the same set of locations.</p>

<p><em>Example 10: nginx Profile with vhosts and locations being created</em></p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
<span class='line-number'>46</span>
<span class='line-number'>47</span>
<span class='line-number'>48</span>
<span class='line-number'>49</span>
<span class='line-number'>50</span>
<span class='line-number'>51</span>
<span class='line-number'>52</span>
<span class='line-number'>53</span>
<span class='line-number'>54</span>
<span class='line-number'>55</span>
<span class='line-number'>56</span>
<span class='line-number'>57</span>
<span class='line-number'>58</span>
<span class='line-number'>59</span>
<span class='line-number'>60</span>
<span class='line-number'>61</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>class profile::linux::nginx {
</span><span class='line'>
</span><span class='line'>  $mail                           = hiera('nginx::default::mail')
</span><span class='line'>  $worker_processes               = hiera('nginx::default::worker_processes')
</span><span class='line'>  $server_tokens              = hiera('nginx::default::server_tokens')
</span><span class='line'>  $nginx_error_log                = hiera('nginx::default::nginx_error_log')
</span><span class='line'>  $http_access_log                = hiera('nginx::default::http_access_log')
</span><span class='line'>  $proxy_cache_path               = hiera('nginx::default::proxy_cache_path')
</span><span class='line'>  $proxy_cache_levels         = hiera('nginx::default::proxy_cache_levels')
</span><span class='line'>  $proxy_cache_keys_zone      = hiera('nginx::default::proxy_cache_keys_zone')
</span><span class='line'>  $proxy_cache_max_size           = hiera('nginx::default::proxy_cache_max_size')
</span><span class='line'>  $names_hash_bucket_size     = hiera('nginx::default::names_hash_bucket_size')
</span><span class='line'>
</span><span class='line'>  #################################################
</span><span class='line'>  # Get the hash of vhosts from Hiera. Extract the hash keys into a list (array).
</span><span class='line'>  #################################################
</span><span class='line'>
</span><span class='line'>  $vhosts                     = hiera('proxy::sites::vhosts')
</span><span class='line'>  $vhostslist                 = keys($vhosts)
</span><span class='line'>
</span><span class='line'>  #################################################
</span><span class='line'>  # Create the base nginx config by passing the nginx module the minimum config that we use across all our systems
</span><span class='line'>  #################################################
</span><span class='line'>
</span><span class='line'>  class { '::nginx':
</span><span class='line'>    mail                      =&gt; $mail,
</span><span class='line'>    worker_processes          =&gt; $worker_processes,
</span><span class='line'>    server_tokens                 =&gt; $server_tokens,
</span><span class='line'>    nginx_error_log           =&gt; $nginx_error_log,
</span><span class='line'>    http_access_log           =&gt; $http_access_log,
</span><span class='line'>    proxy_cache_path          =&gt; $proxy_cache_path,
</span><span class='line'>    proxy_cache_levels            =&gt; $proxy_cache_levels,
</span><span class='line'>    proxy_cache_keys_zone         =&gt; $proxy_cache_keys_zone,
</span><span class='line'>    proxy_cache_max_size      =&gt; $proxy_cache_max_size,
</span><span class='line'>    names_hash_bucket_size        =&gt; $names_hash_bucket_size,
</span><span class='line'>  }
</span><span class='line'>
</span><span class='line'>  ################################################
</span><span class='line'>  # Create the ngingx vhosts (server blocks in nginx config terms). Pass create_resources the hash retrieved from Hiera,
</span><span class='line'>  # into the nginx::resource::vhost resource defined by the nginx module
</span><span class='line'>  ################################################
</span><span class='line'>
</span><span class='line'>  create_resources('::nginx::resource::vhost', $vhosts)
</span><span class='line'>
</span><span class='line'>  define profile::linux::nginx::location {
</span><span class='line'>    ### Creating Locations
</span><span class='line'>    $locations = hiera('proxy::sites::locations')
</span><span class='line'>    $vhostslocations = { vhost =&gt; $name }
</span><span class='line'>
</span><span class='line'>    create_resources('::nginx::resource::location', $locations, $vhostslocations)
</span><span class='line'>  }
</span><span class='line'>
</span><span class='line'>  ################################################
</span><span class='line'>  #
</span><span class='line'>  # This calls the above define per member of $vhostslist array
</span><span class='line'>  #
</span><span class='line'>  ################################################
</span><span class='line'>
</span><span class='line'>  profile::linux::nginx::location { $vhostslist: }
</span><span class='line'>
</span><span class='line'>}</span></code></pre></td></tr></table></div></figure>


<p>So what have we done here?</p>

<p>The first thing is that we&rsquo;ve added an array called <code>$vhostslist</code>, whos
array members are made up of the key names of the <code>$vhosts</code> hash:</p>

<pre><code>$vhostslist = keys($vhosts)
</code></pre>

<p>This gives us the array that we want to iterate over, as discussed in
the Puppet iteration section. The array members in this example will be
&ldquo;SiteA&rdquo; and &ldquo;SiteB&rdquo;, i.e. <code>[ "SiteA", "SiteB" ]</code>.</p>

<p>The second thing we&rsquo;ve added is a new define,
<code>profile::linux::nginx::location</code>:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>define profile::linux::nginx::location {
</span><span class='line'>  ### Creating Locations
</span><span class='line'>  $locations = hiera('proxy::sites::locations')
</span><span class='line'>  $vhostslocations = { vhost =&gt; $name }
</span><span class='line'>
</span><span class='line'>  create_resources('::nginx::resource::location', $locations, $vhostslocations)
</span><span class='line'> }</span></code></pre></td></tr></table></div></figure>


<p>This can be thought of as a function in more general programming
languages, that will iterate over the array <code>$vhostslist</code>. Within this
define we are retrieving the list of locations into a has called
<code>$locations</code>, using another Hiera lookup, on the key
<code>proxy::sites::locations</code> (Yes I&rsquo;m aware this will be done for every
iteration, not optimal). We then create a new hash called
<code>$vhostslocations</code> which contains the key <code>vhost</code> and value <code>$name</code>,
i.e. <code>{ vhost =&gt; $name }</code>.</p>

<p>Once we have the <code>$locations</code> hash and the <code>$vhostslocations</code> hash, we
then call <code>create_resources</code>. Just like the previous time we called
<code>create_resources</code>, the specific resource is defined by the nginx
module, and is called <code>::nginx::resource::location</code>. However, in this
case we&rsquo;re giving the <code>create_resources</code> function two items, not one.
The first item is the list of locations we&rsquo;d like to create, and the
second is the <code>$vhostslocations</code> hash.</p>

<p>The second optional item passed to <code>create_resources</code> (
<code>$vhostslocations</code> ) is an anonymous hash of extra parameters to add to
the resource being created.</p>

<p>This define is then &ldquo;called&rdquo; by the line:</p>

<pre><code>profile::linux::nginx::location { $vhostslist: }
</code></pre>

<p>Before we go further, we need to look at the Hiera data again, and
modify it slightly:</p>

<p><em>Example 11: Modified Hiera data</em></p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>proxy::sites::vhosts:
</span><span class='line'>  SiteA:
</span><span class='line'>    listen_port : 8080
</span><span class='line'>    rewrite_to_https : false
</span><span class='line'>    use_default_location : false
</span><span class='line'>  SiteB:
</span><span class='line'>    listen_port : 8080
</span><span class='line'>    rewrite_to_https : false
</span><span class='line'>    use_default_location : false
</span><span class='line'>
</span><span class='line'>proxy::sites::locations:
</span><span class='line'>  "%{name}_root"
</span><span class='line'>    location : '/'
</span><span class='line'>    ensure : 'present'
</span><span class='line'>    proxy : 'http://serviceA'
</span><span class='line'>  "%{name}_server_status"
</span><span class='line'>    location : '/server-status'
</span><span class='line'>    ensure : 'present'
</span><span class='line'>    stub_status : true</span></code></pre></td></tr></table></div></figure>


<p>The change here is the variable we want interpolated has been changed to
<code>%{name}</code>, and the <code>vhost</code> parameter has been removed.</p>

<p>You&rsquo;ll notice in Example 10 the newly added define suddenly makes use of
a variable called <code>$name</code>. We&rsquo;re also now referencing it in our modified
Hiera config in Example 11.</p>

<p>So what is <code>$name</code>? Well, this goes back to Puppet resources again. The
define <code>profile::linux::nginx::location</code> <strong>is</strong> a Puppet resource, and
as such must be &ldquo;named&rdquo; (and again, named uniquely). When we call the
define:</p>

<pre><code>profile::linux::nginx::location { $vhostslist: }
</code></pre>

<p>We&rsquo;re passing it the array that it iterates over, but under the hood in
a bit of Puppet magic, the &ldquo;name&rdquo; of the resource becomes the value of
the array member. So there will be two resources of type
<code>profile::linux::nginx::location</code>, one named &ldquo;SiteA&rdquo; and the other named
&ldquo;SiteB&rdquo;. Within the scope of each of these resources, Puppet creates and
makes available a variable called <code>$name</code>, which of course is set to the
&ldquo;name&rdquo; of the resource, or in our case &ldquo;SiteA&rdquo; and SiteB&#8221;.</p>

<p>Since we are performing a Hiera lookup within the resource (define)
<code>profile::linux::nginx::location</code>, that Hiera lookup now has access to
all the Puppet variables within that scope (see previous info about
Hiera being passed Puppet variables). Therefore the <code>%{name}</code> Hiera
variable is set to the <code>$name</code> Puppet variable. Magic.</p>

<p>The final piece of the puzzle is the <code>$vhostslocations</code> hash, and the
actual use of the <code>$name</code> variable. According to the <code>create_resources</code>
documentation:</p>

<p>&ldquo;The values given on the third argument are added to the parameters of
each resource present in the set given on the second argument.&rdquo;</p>

<p>So therefore the hash <code>$vhostslocations { vhost =&gt; "$name" }</code> basically
gives the nginx module an extra parameter that is applied to each
location created of &ldquo;vhost => SiteA&rdquo; or &ldquo;vhost => SiteB&rdquo;. This
establishes the relationship between the locations and their parent
vhosts.</p>

<p>Put it all together and we now have a start towards cleanly modelling
nginx configurations in Hiera, without repeating data, and using the
Roles and Profile pattern. This allows us to completely extract site
configuration data from the Puppet DSL, by providing an abstraction
layer to the nginx module (the nginx Profile). I didn&rsquo;t actually touch
upon a Puppet Role here, but once you have your Profile(s) created, the
creation of Roles is generally much simpler, as they should be nothing
more than a collection of Profiles. The links provided at the beginning
of this post on Roles/Profiles should make the rest clear.</p>

<p>So that&rsquo;s basically an end-to-end example (although not necessarily 100%
working) of using Hiera to model nginx, and combining that with an
abstraction layer (the Profile) above the nginx module.</p>

<h2>Possible re-factors</h2>

<ol>
<li>Duplicate data in the vhosts configurations could be reduced using
the same iteration trick used for the location configs.</li>
<li>Removing the Hiera lookup from the <code>profile::linux::nginx::location</code>
resource would prevent repeating the lookup.</li>
<li>Remove the use of the <code>$vhostslocations</code> hash. Use Hiera
interpolation to specify the vhost parameter in the location
resource.</li>
<li>Many others I haven&rsquo;t thought of :)</li>
</ol>


<p>If anyone has any improvements, suggestions, comments or criticisms let
me know at mahhy at undertow dot ca.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[How the current mobile landscape affects developers]]></title>
    <link href="http://engineering.bedegaming.com/blog/2014/10/20/developers-and-the-changing-mobile-landscape/"/>
    <updated>2014-10-20T16:55:00+01:00</updated>
    <id>http://engineering.bedegaming.com/blog/2014/10/20/developers-and-the-changing-mobile-landscape</id>
    <content type="html"><![CDATA[<p>A colleague pointed me towards an interesting <a href="http://www.slideshare.net/robnyman/mobile-trends-web-native">presentation</a> that illustrates some dramatic shifts in the mobile market. I think it&rsquo;s important that mobile app developers take a close look at how this may impact apps they are working on. Here we discuss issues and possible solutions to the problems that may arise.</p>

<!-- more -->


<h2>The mobile OS battle</h2>

<p>Whether this can be classed as a battle anymore is up for debate but currently Android leads the way and now owns approximately 85% of the market, compare that to 2012 when it was hitting 69% and in 2011 it was only 36%! Looking across at iOS which has dropped from 18% to 11% in the same time period it is certainly looking like the two big players are still the main targets for users, Blackberry has virtually disappeared and Windows Phone seems more appealing to developers than consumers.</p>

<p>Another interesting point is the disappearance of the &ldquo;Other&rdquo; OS&rsquo;s. In 2011 this figure occupied 30% of the market, it now comprises a tiny 0.7%. My opinion here is that this is mainly to do with some of the big mobile handset manufactors moving away from Symbian as their primary platform. Samsung and Sony Ericsson have of course moved to Android whereas Nokia have adopted the Windows Phone OS. So what does this mean for developers?</p>

<p><img class="center" src="http://engineering.bedegaming.com/images/smartphone-os-market-share.png" title="Smartphone OS Market Share" alt="Smartphone OS Market Share"></p>

<p><em>Source: <a href="http://www.idc.com/prodserv/smartphone-os-market-share.jsp">idc.com</a></em></p>

<h3>Android fragmentation</h3>

<p>Firstly, the fragmentation of the Android market means there are many devices to support whereas on iOS there are a known set of devices to target. This leads to problems with differing device performance levels, screen resolutions and OS versions. For mobile web apps or sites you can add the usual cross browsers incompatibilities to that list.</p>

<h3>High end devices</h3>

<p>Despite Android&rsquo;s 85% market share dwarfing iOS&rsquo;s 11%, you may be surprised to hear that iOS still holds the greater market share when it comes to the high end devices. This is a key consideration to take into account when you analyse the target audience for your app or wesbite.</p>

<h3>App distribution</h3>

<p>Each OS comes with its own app distribution channel, on iOS we have the App Store and Android the Play Store (we should also try not to forget about the Windows Store). The different stores have their own restrictions on the types of app they host, the Play Store for example does not allow gambling apps and also a varying review process. The native language used to develop apps for each OS also varies:</p>

<ul>
<li>Android - Java</li>
<li>iOS - Objective-C / Swift</li>
<li>Windows - C++ / .NET</li>
</ul>


<p>This sets an obvious challenge to developers looking to publish on each store, is it really worth writing an app 3 times?</p>

<h2>So what can we do about it?</h2>

<p>Ok, I&rsquo;ve listed some of the issues that can arise when thinking about developing your latest app or website now how do we solve these isssues? Lets take a look at dealing with the many different devices on the market today. For me, the key here is to know your target audience and plenty of research. Its also useful to consider what your app or site is going to do, ask yourself these questions:</p>

<ol>
<li>What does my app do?</li>
<li>Will it need good hardware?</li>
<li>Am I willing compromise app experience?</li>
</ol>


<p>Three questions that sound obvious but once answered, can really help narrow down that extensive device list - if your app doesnt include rich graphics or intensive animations then its probably safe to widen the range of handsets you are going to target or if it&rsquo;s a game for example then you probably want to stick with the higher end of the market. Likewise if your app is heavily reliant on rich animations and graphics and a reduced experience is not really an option then again this will limit you to the high end devices.</p>

<h3>Development approach</h3>

<p>So we&rsquo;ve limited our device range but we still have a problem in that we need to build the same app 3 times in a different language to reach the maximum number of people. Or do we? No of course not - there are lots of tools available now that allow developers to write once, run anywhere (and no I dont mean Java!). In fact the aforementioned document talks about how almost half of mobile app developers choose to write apps using something other than the native language.</p>

<h4>Unity3D</h4>

<p>Unity is a hugely popular game development tool, it allows its users to create games for a wide variety of platforms. Its performance is a near match for its native equivilents and the quality of games rendering is second to none.</p>

<p>Skills for Unity tend be more difficult to find when compared to native iOS/Android and HTML5, probably because its popularity mainly stems from the games industry, however there is a large community behind it and a new Unity Store where developers can download assets and plugins for their games.</p>

<p>In my opinion, aside from the skill shortage, where Unity falls down is when it comes to app distruption. As with most channels you still have the review process for the various app stores and each new version must go through a similar review.</p>

<h4>Haxe</h4>

<p>Haxe is a relatively new tool that has been brought to my attention recently, it is source to source complier or <em>transpiler</em> for a more appropriate term. This gives developers the ability to write their app once in the Haxe language and &lsquo;transpile&rsquo; into a variety of native languages, current language support includes:</p>

<ul>
<li>iOS</li>
<li>Android</li>
<li>HTML5</li>
<li>Flash</li>
<li>C#</li>
<li>PHP</li>
<li>C++ and more</li>
</ul>


<p>The toolkit has gained backing from some well known companies like Tivo, Prezi and Zynga to name a few and also has a growing open source community which should mean further advances in the native API&rsquo;s. Where this struggles in my opinion is there will always be issues for transpiled languages where some areas of the API dont work cross platform so you maybe forced to restrict functionality in your app to cater for this. That said I imagine the API&rsquo;s available will cater for the majority of apps.</p>

<p>I&rsquo;m not usually a fan of transpilers, I&rsquo;ll stop now before I start a rant about CoffeeScript (one for another post!), but this one certainly looks to have its place in the market and I will be looking into this more in the near future.</p>

<h4>HTML5 and beyond!</h4>

<p>At Bede we are big adovcates of HTML5 and its surrounding technologies. Our games clients make use of the latest HTML5 API&rsquo;s, Javascript frameworks and CSS3 and our CMS uses a variant of responsive design to cater for varying screen resolutions and devices.</p>

<p>All the major mobile platforms support apps built in HTML5. Whether its an app to be published on the app store built with something like <a href="http://cordova.apache.org/">Apache Cordova</a> or one of its distributions, <a href="http://phonegap.com/">PhoneGap</a> is one of the more popular names or a web app saved from the web - Google and Apple are definitely getting behind the HTML5 revolution! An article over at <a href="http://www.sencha.com/blog/apple-shows-love-for-html5-with-ios-8">Sencha</a> details how iOS 8 adds support for many more HTML5 features, couple this with the recent addition of the &lsquo;Nitro&rsquo; Javascript engine to UIWebView and you can see how Apple are embracing HTML5.</p>

<p><img class="center" src="http://engineering.bedegaming.com/images/ios-html5-support.png" title="iOS HTML5 feature support comparison" alt="iOS HTML5 feature support comparison"></p>

<p><em>Source: <a href="http://caniuse.com">caniuse.com</a></em></p>

<p>Google continue to improve the Android experience by making Chrome the default browser in the latest versions of Android, finally ridding HTML5 developers of the native Android browser (or &lsquo;the IE6 of mobile&rsquo; as I like to call it). Performance used to be the main drawback of this approach but the latest developments with full webGL support meaning  hardware accerlation for HTML5 canvas and more powerful devices hitting the market, this is less of a concern these days.</p>

<p>In my opinion HTML5 is succeeding in becoming <em>the</em> write once, run everywhere choice for mobile app development. Maybe only the ultra high performance games have the performance concern now - for the vast majority of developers we can safely rely on HTML5 to deliver what we need in terms of app development. If done correctly the performance difference should be barely noticeable.</p>

<p>An added bonus is that creating a hybrid app with HTML5 means you can auto update you app without needing to go through a review in the app stores for the new content, deploying the latest version to the web will in turn update the app content. This may seem like a small advantage at first but for an app that may require frequent improvements and many iterations it is an invaluable feature.</p>

<p>As described above HTML5 plays a big part in the products delivered by Bede and based on some figures I was shown recently that indicated 40% of traffic on a popular client site came from mobile devices, I believe we are a good case study on the benefits the technology can bring. Aside from the aesthetics of sites and the rich interfaces we can create using the stack, topics like team structure and recruitment strategy are also key bonus points. Across the different teams in Bede a lot of shared code can be utilised - a repository of less mixins is available to developers and our games clients are written using our Javascript framework. Traditionally HTML5 skills have been easier to recruit for than traditional tech skills associated with mobile development, this has allowed Bede to quickly grow a highly talented team.</p>

<p>The main advantage HTML5 gives Bede over its competitors is the ability to rapidly produce rich applications that are highly configurable to the point where it is difficult to identify the software running underneath, compare 2 of our Bingo clients with 2 from a competitor and you will see what I mean!</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Who is your Brent?]]></title>
    <link href="http://engineering.bedegaming.com/blog/2014/10/16/who-is-your-brent/"/>
    <updated>2014-10-16T18:19:00+01:00</updated>
    <id>http://engineering.bedegaming.com/blog/2014/10/16/who-is-your-brent</id>
    <content type="html"><![CDATA[<p>In the book <a href="http://www.amazon.co.uk/Phoenix-Project-DevOps-Helping-Business-ebook/dp/B00AZRBLHO/ref=sr_1_1?s=books&amp;ie=UTF8&amp;qid=1413480244&amp;sr=1-1&amp;keywords=the+phoenix+project">The Phoenix Project</a> one of the primary foils of the &ldquo;hero&rdquo; is a guy named Brent. Brent is critical to successful work. Production incident? Call Brent. Complex database query? Brent&rsquo;s your guy. Tracing down network packet drops? Brent is already on it.  On the face of it, he is what every ops team wants twenty of, but as the book shows it is easy to become so critically dependent on one person that they become a bottleneck for the organisation. Also, Brent has several bad habits. He drops everything he&rsquo;s doing to sort out what ever is being screamed about loudest, regardless of its actual priority. He&rsquo;s also a knowledge silo - because Brent built half the complex systems in the business, he knows <!-- more -->how to solve tricky problems with them all, but all the knowledge is in his head, to the point where most of the rest of the team won&rsquo;t touch those areas. Why would they? Brent can solve the issue in a tenth of the time, and more safely.</p>

<h2>Removing the Bottleneck</h2>

<p>Much of the middle of the book is about how a mentor gets our hero thinking about how to remove that bottleneck. They tried hiring expensive experienced ops people. That failed because they still didn&rsquo;t have the knowledge of Brent, or if they gained it, it was also only in their heads. Part of the solution is to ensure that Brent is literally not allowed to touch the keyboard in production incidents, rather he must explain to a junior staff member how to step through the problems, and document the steps taken, and how to deal with the issue in future. The second part is ensuring visibility of all the work that Brent actually does, not just the stuff that was planned for him. This is one of the other key themes of the book - planned work vs unplanned work.</p>

<h2>Unplanned Work</h2>

<p>Unplanned work is a killer. Production incidents, sneaky off-the-books &ldquo;can you just get something working for me&rdquo; projects from senior management bypassing the project management / prioritisation functions, fixing another persons work because it&rsquo;s been &ldquo;done wrong&rdquo;. Not only does it not appear on your projections of how well you are doing, but it also involves parking what you should be doing, called <em>context switching</em>, or leaving <em>work in progress</em> (WIP). Gaining visibility of all the unplanned work Brent was doing was key to reducing that unplanned work. Sometimes this was even achieved by yelling at very senior management who were demanding that they &ldquo;wanted Brent to look at the issue because he&rsquo;s the best&rdquo;, despite the fact that others were already doing that piece of work.</p>

<p>As Brent&rsquo;s unplanned work went down, it became possible to leverage his actual skillset in high value operations - such as early design review and planning. Without the fire-fighting he is able to take part in processes that reduce the amount of fire-fighting! A virtuous cycle indeed.</p>

<h2>A Person is not a workstation</h2>

<p>In a twist in the later part of the book, the mysterious mentor points out to the hero, via manufacturing analogies, that a Brent is not a work centre or work station. That is, on on the macro level, a person is not a bottleneck, the function that they are carrying out is. In manufacturing you slow down your production of new work items to the speed where they can all be consumed by the next stage without queueing. One of these stations will be the slowest. That is your limiting factor or your bottleneck. (Note - a bottleneck does not specifically mean &ldquo;bad&rdquo;. No matter how optimal your process gets <em>something</em> will be the slowest part).</p>

<h2>Software Development Workstations</h2>

<p>In the software development world, your &ldquo;work stations&rdquo; are things like requirements gathering, planning, architecture and design, implementation, code review, QA testing, deployment to an environment (including production or testing environments). Where is your limiting factor? What stage holds you up the most. One of the great messages in the book is (paraphrased)</p>

<blockquote><p>Any improvements to a process that is not your bottleneck is a fake improvement</p></blockquote>

<p>Basically - because WIP is so bad, anything that does not stop WIP building up at one cost centre is not really reducing the overall turnaround time for work from inception to successful production. You should <em>only</em> focus on improving the bottleneck. When that is no longer the bottleneck, look to the next one.</p>

<h2>Identifying your Bottleneck</h2>

<p>It&rsquo;s actually quite easy to do. Draw a diagram with a box for each process you have from requirements through to in production (generally a straight flow diagram). For each, identify whether they generally have a queue of items from the previous step. Now go from right to left until you find the first item that has a queue. That is your bottle neck.</p>

<p><strong>Example</strong></p>

<blockquote><p>The average queue of stories in the backlog awaiting development work is about 15 items. The average number of stories awaiting QA is 5. The &ldquo;quick&rdquo; answer is to say that clearly the biggest problem is in development - they are coping least well! But think what would happen if you improved that part of the process. QA already has a queue of work - it would only get bigger. There is no point in resolving how much work development can process until QA is no longer the bottleneck.</p></blockquote>

<p>As a real world reminder - here is an recent example from our own boards. You can see that we are building up a bottleneck on QA process. We&rsquo;ve already gone through reviewing the underlying causes. We&rsquo;re tackling this area before re-assessing our next bottleneck.</p>

<p><img class="center" src="http://engineering.bedegaming.com/images/QA-bottleneck-example.png" width="500" height="750" title="image" alt="images"></p>

<h2>Conclusion</h2>

<p>Where is your bottleneck? Who is your Brent? Find them and improve them first, because all other improvements are irrelevant!</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[The Dev-ops 80-20 Rule For Selecting A Database]]></title>
    <link href="http://engineering.bedegaming.com/blog/2014/10/16/the-dev-ops-80-20-rule-for-selecting-a-database/"/>
    <updated>2014-10-16T15:23:57+01:00</updated>
    <id>http://engineering.bedegaming.com/blog/2014/10/16/the-dev-ops-80-20-rule-for-selecting-a-database</id>
    <content type="html"><![CDATA[<p>You&rsquo;re probably already familiar with the 80-20 rule, less catchily known as the <a href="http://en.wikipedia.org/wiki/Pareto_principle">pareto principle</a> - the idea that you spend about 20% of the time it takes to complete a project building out the first 80% of the features, with the remaining 80% of the duration to complete the elusive final 20%.  There are countless applications of this idea - kind of like when you’ve just learnt a new word, examples start to crop up everywhere.  The most recent example I’ve come across describes the amount of time spent working with persistence technologies from the point of view of developers and operations.  But first some background.
 <!-- more -->
In the days of working on back office software, if there wasn’t a strong opinion already about how to solve a problem, developers were free to pick tools that met their basic checklist - will it work in production? Will the project cover the costs if they exist? And most importantly, HOW SHINY IS IT?</p>

<p>I’m as guilty as the next developer of having picked tools to work with based primarily on how much I wanted to play with them.  Being an easy tool to code with use generally made my life as a developer easier, but it was also an easy sell to management - if it takes me, the expensive developer, less time to build a solution with, it must be good for the project.  Of course, over time, lots of counter examples have cropped up: just throw “rails performance bottleneck” or “entity framework SQL fail” into google and read to learn what happens when developer magic sauce is spread liberally and allowed to determine the architecture.</p>

<p>A single instance of Bede&rsquo;s wallet can generate in the region of 10Gb data / day. It turns out that when you need to keep everything, and the product is growing daily, managing an additional 10Gb of data every day can be moderately painful.  Painful to the extent that we have an operations team, one of whose key roles is essentially to keep everything running.  Over the last year or so we’ve scaled vertically, <a href="http://en.wikipedia.org/wiki/2147483647">run out of 32-bit integers</a>, added lots of database nodes, added data centres and strategised about archiving operational data.</p>

<p>Turns out I had fallen victim to the most common of easy vs simple fails.  In architecting the original product, we focussed on tools with which we were familiar - those that were close at hand; and therefore easy for the developer to use.  In this case MySql.  Now, MySql is extremely capable of scaling to massive data volumes, it’s currently powering numerous huge databases like Google Adwords and Facebook <a href="http://thenextweb.com/dd/2014/03/27/facebook-google-linkedin-twitter-launch-webscalesql-custom-version-mysql-massive-databases/">albeit in a much customised form</a>.  But scaling traditional RDBMs does come with a significant ops overhead.  For Bede&rsquo;s wallet, the data architecture at the code level is now pretty mature, we almost never add new data fields.  But as a business, we spend a lot of time working with the data at the persistence level - just to keep the lights on and the replicas fresh.</p>

<p>On reflection, it seems that we chose a persistence technology ignorant of the devops 80-20 rule.  I’d estimate that to date, of all the many, many man-months of time Bede&rsquo;s IT department has spent building and maintaining this product on MySql, about 20% of that time (if not less) was spent by developers building the original product, during which we benefitted from the wealth of developer tools and documentation at our disposal - it was easy to do.  At least 80% of the time, and therefore cost, has been spent by the operations team, keeping things going.</p>

<p>With my <a href="http://www.infoq.com/presentations/Simple-Made-Easy-QCon-London-2012">Simple made Easy</a> hat on, and my 20/20 hindsight goggles engaged, it was short-sighted to select the easy, comfortable technology, the one that we had experience with, without understanding how the total cost of ownership (TCO) for the decision would be contained mostly in maintenance down the line, rather than the comparatively minimal initial build.</p>

<p>So what else can we do? I think the main learning point has been to select technology with a stronger consideration for TCO.  A less smooth developer experience may well be preferable to more complex operational maintenance strategy. The persistence marketplace these days is awash with distributed database solutions with significantly improved cluster management and auto-healing capabilities, offering different types of storage and varying levels of consistency.  Some of them <a href="https://foundationdb.com/">even support ACID</a>.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Introducing Bede Engineering]]></title>
    <link href="http://engineering.bedegaming.com/blog/2014/10/15/introducing-engineering-dot-bedegaming-dot-com/"/>
    <updated>2014-10-15T18:13:05+01:00</updated>
    <id>http://engineering.bedegaming.com/blog/2014/10/15/introducing-engineering-dot-bedegaming-dot-com</id>
    <content type="html"><![CDATA[<p>A long time in the hoping, not so long in the making (thanks to <a href="http://octopress.org">Octopress</a> and <a href="https://github.com/wallace/justin-kelly-theme">Justin Kelly&rsquo;s Theme</a>), we&rsquo;re pretty excited to finally be able to show you our new engineering microsite.</p>

<p>We&rsquo;ve got some great posts lined up: everything from how we manage our army of servers to our approach to continuous delivery. In the meantime, you can browse some of our open source software using the links on the right.</p>
]]></content>
  </entry>
  
</feed>
